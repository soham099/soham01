<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Soham Bonnerjee&#39;s Home Page</title>
    <link>/</link>
      <atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    <description>Soham Bonnerjee&#39;s Home Page</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Sat, 28 Mar 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/img/icon-192.png</url>
      <title>Soham Bonnerjee&#39;s Home Page</title>
      <link>/</link>
    </image>
    
    <item>
      <title>eSIR - An Epidemiological Model incoportating Quarantining Effect</title>
      <link>/post/esir-modelling/</link>
      <pubDate>Sat, 28 Mar 2020 00:00:00 +0000</pubDate>
      <guid>/post/esir-modelling/</guid>
      <description>&lt;h1 id=&#34;current-scenario-in-india&#34;&gt;Current Scenario in INDIA&lt;/h1&gt;
&lt;p&gt;Taking cue from global powerhouses failing catastrophically to contain the onslaught on life that&#39;s been lunched by Covid-19, Prime Minister of India Shri Narendra Modi issued instructions for a nationwide &lt;em&gt;Lockdown&lt;/em&gt; starting from 25 March&#39;20 to 14 April&#39;20, wth possible plans for further extension. The decision have been welcomed and lauded by various researchers and scientists alike, esopecially after countries like USA and Italy acted too late to a possibly aggravated situation. But why this praise? In this post, we&#39;ll find out how lockdown and other forms of quarantining helps contain the infection.&lt;/p&gt;
&lt;p&gt;But before that, a gentle reminder of what we are up against: till date, Covid-19 virus has affected $722$ people in India, and $486702$ people worldwide and has claimed $16$ lives in India till now. We have discussed about the origin of the virus and possible measures to contain infection in our last &lt;a href=&#34;https://soham01.netlify.com/post/covid19-project/&#34;&gt;post&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;This is a post to show how we can incorporate quarantining effects in statistical modelling of epidemiology. In past few days of Shelter-in-place lockdown situation in Kolkata (and throughout the whole India from today onwards), me and one of my ingenious friend &lt;a href=&#34;https://subroy13.github.io/&#34;&gt;Subhrajyoty Roy&lt;/a&gt; (we were attending the same college before lockdown to purse Masters degree in Statistics), was reading about different epidemiological models available in the literature and using it to generate projections for the number of infected people in India, and this is a result of that reading and further independent developements.&lt;/p&gt;
&lt;h1 id=&#34;loading-the-packages-and-the-dataset&#34;&gt;Loading the Packages and the Dataset&lt;/h1&gt;
&lt;p&gt;We are using the same dataset source as before, except that we have updated it to include some of the current observations. Similar to before, we shall be using &lt;code&gt;dplyr&lt;/code&gt; for data manipulation and summarization, &lt;code&gt;lubridate&lt;/code&gt; for handling dates and times, and &lt;code&gt;ggplot2&lt;/code&gt; for plotting.&lt;/p&gt;
&lt;p&gt;However, due to some Monte Carlo simulation later, we shall be needing &lt;code&gt;rjags&lt;/code&gt; and we shall use &lt;code&gt;gtools&lt;/code&gt; for specification of some useful probability distributions.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(readr)
library(dplyr)
library(lubridate)
library(ggplot2)
library(rjags)
library(gtools)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, finally we load the updated dataset, which I have already downloaded from &lt;a href=&#34;https://github.com/CSSEGISandData/COVID-19&#34;&gt;JHU CSSE&lt;/a&gt;, and manipulated to get the required form of data using the code discussed in my previous post &lt;a href=&#34;https://subroy13.github.io/post/post6/&#34;&gt;here&lt;/a&gt;. We shall take a look at the last few columns to see how much we have updated.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dat &amp;lt;- read_csv(&#39;./datasets/covid-19-data.csv&#39;)
knitr::kable(tail(dat, 3))
&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;State&lt;/th&gt;
&lt;th&gt;Country&lt;/th&gt;
&lt;th&gt;Lat&lt;/th&gt;
&lt;th&gt;Long&lt;/th&gt;
&lt;th&gt;Date&lt;/th&gt;
&lt;th&gt;Confirmed&lt;/th&gt;
&lt;th&gt;Deaths&lt;/th&gt;
&lt;th&gt;Recovered&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Zhejiang&lt;/td&gt;
&lt;td&gt;China&lt;/td&gt;
&lt;td&gt;29.1832&lt;/td&gt;
&lt;td&gt;120.0934&lt;/td&gt;
&lt;td&gt;2020-03-24&lt;/td&gt;
&lt;td&gt;1240&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;1221&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Zhejiang&lt;/td&gt;
&lt;td&gt;China&lt;/td&gt;
&lt;td&gt;29.1832&lt;/td&gt;
&lt;td&gt;120.0934&lt;/td&gt;
&lt;td&gt;2020-03-25&lt;/td&gt;
&lt;td&gt;1241&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;1221&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Zhejiang&lt;/td&gt;
&lt;td&gt;China&lt;/td&gt;
&lt;td&gt;29.1832&lt;/td&gt;
&lt;td&gt;120.0934&lt;/td&gt;
&lt;td&gt;2020-03-26&lt;/td&gt;
&lt;td&gt;1243&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;1222&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h1 id=&#34;description-of-esir-model&#34;&gt;Description of eSIR Model&lt;/h1&gt;
&lt;p&gt;The eSIR (Extended SIR) model is really similar to the SIR model, except for the fact that it includes  a function that parametrizes the quarantining effects. As with SIR modelling, it has 3 different compartments, of states in which a person can be. This model has been developed very recently by &lt;a href=&#34;https://www.medrxiv.org/content/10.1101/2020.02.29.20029421v1.full.pdf&#34;&gt;Wang et al.&lt;/a&gt; The states are as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;graph LR
  A(Susceptible) --&amp;gt;|&amp;quot;&amp;amp;#946&amp;amp;#960(t)&amp;quot;| B(Infected)
  B --&amp;gt;|&amp;amp;#947| C(Removed)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As described in previous &lt;a href=&#34;https://subroy13.github.io/post/post6/&#34;&gt;post&lt;/a&gt;, &lt;strong&gt;Susceptibles&lt;/strong&gt; are the general population, who is susceptible to get the disease from an infectious person. &lt;strong&gt;Infected&lt;/strong&gt; state reperesents the persons who have the symptoms of the infection and is able to spread it. And finally, &lt;strong&gt;Recovered / Removed&lt;/strong&gt; is the state when a person is recovered from the disease and gain immunity to it, or is dead. Let, $Y_t^S, Y_t^I, Y_t^R$ denotes the proportion of people in these states respectively at the time $t$. Note that $Y_t^S + Y_t^I + Y_t^R = 1$.  $\pi(t)$ denotes the proportion of people transiting from &lt;strong&gt;Susceptible&lt;/strong&gt; to &lt;strong&gt;Infected&lt;/strong&gt; state at time $t$, with the &lt;em&gt;proportion&lt;/em&gt; being commensurate to the proportion of people transiting from &lt;strong&gt;Susceptible&lt;/strong&gt; to &lt;strong&gt;Infected&lt;/strong&gt; state at time $t$ in the original SIR modelling. Thus We can vary $\pi(t)$ from time to time to perfectly capture the effect of quarantining. In other words, the rate at which a susceptible person becomes infected is not a time varying proportion, namely $\beta \pi(t)$, where $\beta$ is the usual rate of transmission of the disease, while $\pi(t)$ is the quarantining effect which might restrict movements of general public in order to make the effective transmission rate lower than the usual quantity $\beta$.&lt;/p&gt;
&lt;p&gt;Let $\theta_t=(\theta_t^S, \theta_t^I, \theta_t^R)^T$ be the vector of underlying prevalence of the population in these three states. Since $Y_t^S, Y_t^I, Y_t^R$ are proportions, we model them via Beta distribution:&lt;/p&gt;
&lt;p&gt;$$\begin{align}
Y_t^I \mid \theta_t, \tau \sim \text{Beta}(\lambda^I\theta_t^I,\lambda^I(1-\theta_t^I))\\\&lt;br&gt;
&amp;amp; \\\&lt;br&gt;
Y_t^R \mid \theta_t, \tau \sim \text{Beta}(\lambda^R\theta_t^R,\lambda^R(1-\theta_t^R))\\\&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;where $\tau=(\beta, \gamma, \theta_0^T, \kappa, \lambda^I, \lambda^R)^T$, $\beta$, $\gamma$ are as in SIR model; $\kappa$, $\lambda^I, \lambda^R$ are parameters governing the latent process we&#39;ll define soon.&lt;/p&gt;
&lt;p&gt;Since $\theta_t$ is a probability, we specify a Dirichlet model for it:&lt;/p&gt;
&lt;p&gt;$$\theta_t \mid \theta_{t-1}, \tau \sim \text{Dirichlet} (k f(\theta_{t-1}, \beta, \gamma))$$&lt;/p&gt;
&lt;p&gt;These together is called a Beta-Dirichlet State Space Model.&lt;/p&gt;
&lt;p&gt;Here $f(\cdot)$ is the solution of the system of ODEs:&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\dfrac{d\theta_t^S}{dt} &amp;amp; = -\pi(t)\beta \theta_t^S \theta_t^I\\\&lt;br&gt;
&amp;amp; \\\&lt;br&gt;
\dfrac{d\theta_t^I}{dt} &amp;amp; = \pi(t)\beta \theta_t^S \theta_t^I - \gamma \theta_t^I\\\&lt;br&gt;
&amp;amp; \\\&lt;br&gt;
\dfrac{d\theta_t^R}{dt} &amp;amp; = \gamma \theta_t^I\\\&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;and this is exactly where the SIR modelling takes place. We solve this system of ODEs via &lt;em&gt;Runge-Kutta&lt;/em&gt;(RK4) approximation.&lt;/p&gt;
&lt;p&gt;To implement the Markov Chain Monte Carlo method, we need to specify prior for the hyperparameters $\tau=(\beta, \gamma, \theta_0^T, \kappa, \lambda^I, \lambda^R)^{\top}$. We do that as follows:&lt;/p&gt;
&lt;p&gt;We initialize $\theta_0$ via a distribution that uses the observed data:&lt;/p&gt;
&lt;p&gt;$$\begin{align}
\theta_0^I \sim \text{Beta}(1, \dfrac{1}{Y_1^I})\\\&lt;br&gt;
&amp;amp; \\\&lt;br&gt;
\theta_0^R \sim \text{Beta}(1, \dfrac{1}{Y_1^R})\\\&lt;br&gt;
&amp;amp; \\\&lt;br&gt;
\theta_0^S= 1-\theta_0^I-\theta_0^R\\\&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;We specify the other hyperparameters according to the &lt;a href=&#34;https://arxiv.org/pdf/1007.0908.pdf&#34;&gt;SARS data&lt;/a&gt; in Hong-Kong.&lt;/p&gt;
&lt;p&gt;$$\begin{align}
R_0= \dfrac{\beta}{\gamma} \sim \text{Log}\mathbb{N}(1.099,0.096) \implies \mathbb{E}(R_0)=3.15, \mathbb{V}(R_0)=1 \\\&lt;br&gt;
&amp;amp; \\\&lt;br&gt;
\gamma \sim \text{Log}\mathbb{N}(-2.955,0.910) \implies \mathbb{E}(\gamma)=0.0117, \mathbb{V}(\gamma)=0.01 \\\&lt;br&gt;
&amp;amp; \\\&lt;br&gt;
k \sim \text{Gamma}(2, 0.0001)\\\&lt;br&gt;
&amp;amp;  \\\&lt;br&gt;
\lambda^I \sim \text{Gamma}(2, 0.0001)\\\&lt;br&gt;
&amp;amp; \\\&lt;br&gt;
\lambda^R \sim \text{Gamma}(2, 0.0001)\\\&lt;br&gt;
\end{align}$$&lt;/p&gt;
&lt;p&gt;Now suppose , data upto time point $t_0$ are observed: $(Y_1, \cdots Y_{t_0})$. We want to predict upto time point $T$. To this end, we generate $M$ MCMC samples, such that for $m \in {1,\cdots, M}$, $(Y_{t_0+1}^{(m)}, \cdots, Y_T)$ is a draw from $Y_t \mid \theta_t, \tau$. The algorihm is described below:&lt;/p&gt;
&lt;p&gt;for $m$ in $1, \cdots, M$&lt;/p&gt;
&lt;p&gt;$\qquad$  for $t$ in $t_0+1,\cdots, T$,&lt;/p&gt;
&lt;p&gt;$\qquad \qquad$  Draw $\theta_t^{(m)}$ from $[\theta_t \mid \theta_{t-1}^{(m)}, \tau^{(m)}]$.&lt;/p&gt;
&lt;p&gt;$\qquad \qquad$  Draw $Y_t^{(m)}$ from $[Y_t \mid \theta_{t}^{(m)}, \tau^{(m)} ]$&lt;/p&gt;
&lt;p&gt;Finally for each time point $t$, $t= t_0+1,\cdots, T$ estimate $Y_t$ by $\hat{Y}_t=\dfrac{1}{M}\displaystyle \sum_{m=1}^M Y_t^{(m)}$.&lt;/p&gt;
&lt;h1 id=&#34;estimation-of-esir-model&#34;&gt;Estimation of eSIR Model&lt;/h1&gt;
&lt;h2 id=&#34;initialization&#34;&gt;Initialization&lt;/h2&gt;
&lt;p&gt;Note that, we wish to have a lognormal distribution $R_0 \sim LogN(\mu, \sigma^2)$, such that, $E(R_0), Var(R_0)$ is at a specified value. The specific reason is that, $R_0 = \beta_0 / \gamma_0$, which is a positive quantity, hence is better modelled by a gamma or lognormal distribution than a normal distribution, which has support as the whole of real line. Therefore, given $E(R_0) = a$, and $Var(R_0) = b$, we wish to figure out $\mu, \sigma$, the parmeters of the lognormal distribution. This can be obtained through the following simple formula and is implemented in the following function.&lt;/p&gt;
&lt;p&gt;$$\sigma^2 = \log\left( \dfrac{Var(R_0)}{E(R_0)^2} +1 \right) \qquad \qquad \mu = \log(E(R_0)) - \dfrac{\sigma^2}{2}$$&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;lognorm.param&amp;lt;-function(mu0,var0){
  var &amp;lt;- log(var0/mu0^2+1)
  mu &amp;lt;- log(mu0)-var/2
  return(round(c(mu,var),3))
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, we specify some control parameters, which specifies the initial $E(R_0), Var(R_0)$ and some other parameters, as well as the parameters for the markov chain (like the length of the chain, the number of parallel chains to construct in order to speed up the process, number of samples to define burn in period etc.) You may want to skip these technical details for now.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;init.params &amp;lt;- list(R0 = 3.15, R0_sd = 1, gamma0 = 0.0117, gamma0_sd = 0.1)
control.params &amp;lt;- list(nchain=4, nadapt=1e4, ndraw=5e2, thin=10, nburnin=2e2)
control.params$mclen &amp;lt;- round(control.params$ndraw / control.params$thin) * control.params$nchain    #number of MCMC draws in total
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;performing-mcmc&#34;&gt;Performing MCMC&lt;/h2&gt;
&lt;p&gt;Now, we shall be creating a function called &lt;code&gt;do.MCMC&lt;/code&gt; which takes the observed proportion of Infected (I), Removed ( R ), then the value of the function $\pi(t)$ till the observed time period (and the control parameters). Then, it shall perform the MCMC step by generating the posterior sampels, and it shall output that posterior samples, which we shall later use to generate predictions, as well as get estimates.&lt;/p&gt;
&lt;h3 id=&#34;defining-the-jags-code&#34;&gt;Defining the JAGS Code&lt;/h3&gt;
&lt;p&gt;The very first thing to implement MCMC or any Bayesian Computation in &lt;code&gt;rjags&lt;/code&gt; is the specification of a JAGS code. JAGS is the acronym for &lt;a href=&#34;http://mcmc-jags.sourceforge.net/&#34;&gt;&lt;strong&gt;Just Another Gibbs Sampler&lt;/strong&gt;&lt;/a&gt;, which is a program for simulation from Bayesian hierarchical models using Markov chain Monte Carlo (MCMC), developed by Martyn Plummer.&lt;/p&gt;
&lt;p&gt;JAGS code is mainly created based on two simple operations.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;An assignment operator &amp;ldquo;&amp;lt;-&amp;rdquo; is used to denote a deterministic relation.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A tilde operator &amp;ldquo;~&amp;rdquo; is used to denote a stochastic relation. In this case, we have a probability distribution on right hand side, according to which the left hand side variable is being generated.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Based on the above operations, the following JAGS code creates the Bayesian model described above.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;model.string &amp;lt;- paste0(&amp;quot;
             model{
                   for(t in 2:(T_obs+1)){
                   Km[t-1,1] &amp;lt;- -beta*pi[t-1]*theta[t-1,1]*theta[t-1,2]
                   Km[t-1,9] &amp;lt;- gamma*theta[t-1,2]
                   Km[t-1,5] &amp;lt;- -Km[t-1,1]-Km[t-1,9]
                   Km[t-1,2] &amp;lt;- -beta*pi[t-1]*(theta[t-1,1]+0.5*Km[t-1,1])*(theta[t-1,2]+0.5*Km[t-1,5])
                   Km[t-1,10] &amp;lt;- gamma*(theta[t-1,2]+0.5*Km[t-1,5])
                   Km[t-1,6] &amp;lt;- -Km[t-1,2]-Km[t-1,10]
                   Km[t-1,3] &amp;lt;- -beta*pi[t-1]*(theta[t-1,1]+0.5*Km[t-1,2])*(theta[t-1,2]+0.5*Km[t-1,6])
                   Km[t-1,11] &amp;lt;- gamma*(theta[t-1,2]+0.5*Km[t-1,6])
                   Km[t-1,7] &amp;lt;- -Km[t-1,3]-Km[t-1,11]
                   Km[t-1,4] &amp;lt;- -beta*pi[t-1]*(theta[t-1,1]+Km[t-1,3])*(theta[t-1,2]+Km[t-1,7])
                   Km[t-1,12] &amp;lt;- gamma*(theta[t-1,2]+Km[t-1,7])
                   Km[t-1,8] &amp;lt;- -Km[t-1,4]-Km[t-1,12]
                   alpha[t-1,1] &amp;lt;- theta[t-1,1]+(Km[t-1,1]+2*Km[t-1,2]+2*Km[t-1,3]+Km[t-1,4])/6
                   alpha[t-1,2] &amp;lt;- theta[t-1,2]+(Km[t-1,5]+2*Km[t-1,6]+2*Km[t-1,7]+Km[t-1,8])/6
                   alpha[t-1,3] &amp;lt;- theta[t-1,3]+(Km[t-1,9]+2*Km[t-1,10]+2*Km[t-1,11]+Km[t-1,12])/6
                   theta[t,1:3] ~ ddirch(k*alpha[t-1,1:3])
                   I[t-1] ~ dbeta(lambdaI*theta[t,2],lambdaI*(1-theta[t,2]))
                   R[t-1] ~ dbeta(lambdaR*theta[t,3],lambdaR*(1-theta[t,3]))
                  }
                  theta[1,1] &amp;lt;-  1- theta[1,2]- theta[1,3]
                  theta[1,2] ~ dbeta(&amp;quot;,1,&amp;quot;,&amp;quot;,1/I[1],&amp;quot;)
                  theta[1,3] ~ dbeta(&amp;quot;,1,&amp;quot;,&amp;quot;,1/R[1],&amp;quot;)
                  gamma ~  dlnorm(&amp;quot;,lognorm_gamma_param[1],&amp;quot;,&amp;quot;,1/lognorm_gamma_param[2],&amp;quot;)
                  R0 ~ dlnorm(&amp;quot;,lognorm_R0_param[1],&amp;quot;,&amp;quot;,1/lognorm_R0_param[2],&amp;quot;)
                  beta &amp;lt;- R0*gamma
                  k ~  dgamma(2,0.0001)
                  lambdaI ~ dgamma(2,0.0001)
                  lambdaR ~ dgamma(2,0.0001)
               }
            &amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here, &lt;code&gt;init.params&lt;/code&gt; are to be passed accordingly in &lt;code&gt;lognorm.param&lt;/code&gt; function to obtain the &lt;code&gt;lognorm_gamma_param&lt;/code&gt; and &lt;code&gt;lognorm_R0_param&lt;/code&gt; variables.&lt;/p&gt;
&lt;h3 id=&#34;performing-mcmc-1&#34;&gt;Performing MCMC&lt;/h3&gt;
&lt;p&gt;Now, once we have the &lt;code&gt;model.string&lt;/code&gt; containing the JAGS code, we need to open a connection object to that string. Because, &lt;code&gt;rjags&lt;/code&gt; expect the JAGS code to be written in a file, a connection object can gimick the behavior of a file, just based on that string. Once we have the JAGS code ready, passing the data nodes in the JAGS model helps us in creating the posterior model.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;model.spec &amp;lt;- textConnection(model.string)
posterior &amp;lt;- jags.model(model.spec, data=list(&#39;I&#39;=I,&#39;R&#39;=R,&#39;T_obs&#39;=T_obs,&#39;pi&#39;=pi), 
                    n.chains =control.params$nchain, n.adapt = control.params$nadapt)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, we first update the posterior for the burn-in period. In this time, the posterior generates samples are not close to the original sample, and hence we need to discard them. Typically, we set burn-in to be about $2000$ iterations. After that, we pass&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;update(posterior, control.params$nburnin) # update the posterior for burn in times, for this time, do not monitor anything
jags_sample &amp;lt;- jags.samples(posterior, c(&#39;theta&#39;,&#39;gamma&#39;,&#39;R0&#39;,&#39;beta&#39;,&#39;I&#39;,&#39;lambdaI&#39;,&#39;lambdaR&#39;,&#39;k&#39;),
                        n.iter = control.params$ndraw * control.params$nchain,
                        thin = control.params$thin)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So, we combine these into a function called &lt;code&gt;do.MCMC&lt;/code&gt; which we shall use later.&lt;/p&gt;
&lt;h2 id=&#34;forecasting-using-esir-model&#34;&gt;Forecasting using eSIR model&lt;/h2&gt;
&lt;p&gt;Now, since we have the MCMC samples obtained as the output of &lt;code&gt;do.MCMC&lt;/code&gt; function, we can extend the chain using the exact simulation of the process described by the model above, and then, we can obtain the estimates of the proportion of infected and recovered people, as well as the confidence interval for that proportion.&lt;/p&gt;
&lt;p&gt;Again, we shall create &lt;code&gt;forecast.SIR&lt;/code&gt; function which takes in the output of &lt;code&gt;do.MCMC&lt;/code&gt;, and then run the simulation chains starting from the MCMC samples. Finally, it computes the estimates and confidence intervals for the estimates of proportion of infected and removed from the samples from all the chains.&lt;/p&gt;
&lt;h3 id=&#34;extract-components-of-mcmc-samples&#34;&gt;Extract components of MCMC samples&lt;/h3&gt;
&lt;p&gt;Here, we extract the components of MCMC samples from the output of &lt;code&gt;do.MCMC&lt;/code&gt; function.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# extract components from mcmc samples 
theta_pre &amp;lt;- array(as.mcmc.list(mcmc_sample$theta)[[1]], dim = c(control.params$mclen, T_obs+1, 3))
R0_pre &amp;lt;- as.mcmc.list(mcmc_sample$R0)[[1]]
gamma_pre &amp;lt;- as.mcmc.list(mcmc_sample$gamma)[[1]]
beta_pre &amp;lt;- as.mcmc.list(mcmc_sample$beta)[[1]]
lambdaI_pre &amp;lt;- as.mcmc.list(mcmc_sample$lambdaI)[[1]]
lambdaR_pre &amp;lt;- as.mcmc.list(mcmc_sample$lambdaR)[[1]]
k_pre &amp;lt;- as.mcmc.list(mcmc_sample$k)[[1]]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We also initialize blank arrays to store the future forecasts. Here, &lt;code&gt;T_new&lt;/code&gt; is the number of time points for which new forecasting is to be done.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;theta_post &amp;lt;- array(0, dim=c(control.params$mclen, T_new, 3))
I_post &amp;lt;- matrix(NA, nrow=control.params$mclen, ncol=T_new)
R_post &amp;lt;- matrix(NA, nrow=control.params$mclen, ncol=T_new)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;peform-forecasting&#34;&gt;Peform Forecasting&lt;/h3&gt;
&lt;p&gt;The following piece of code basically performs the forecasting starting from the last obtained posterior samples as obtained by MCMC. Now, let us go through the code step by step.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;for(l in 1:control.params$mclen){
    
    thetalt1 &amp;lt;- theta_pre[l, T_obs+1, 1]
    thetalt2 &amp;lt;- theta_pre[l, T_obs+1, 2]
    thetalt3 &amp;lt;- theta_pre[l, T_obs+1, 3]
    betal &amp;lt;- beta_pre[l]
    gammal &amp;lt;- gamma_pre[l]
    kt &amp;lt;- k_pre[l]
    lambdaIl &amp;lt;- lambdaI_pre[l]
    lambdaRl &amp;lt;- lambdaR_pre[l]
    if (betal&amp;lt;0 | gammal&amp;lt;0 | thetalt1&amp;lt;0 | thetalt2&amp;lt;0 |thetalt3&amp;lt;0) { 
      next 
    }
    
    
    for(t in 1:T_new ){
      # perform runge kutta
      Km &amp;lt;- numeric(12)
      alpha_post &amp;lt;- numeric(3)
      
      Km[1] &amp;lt;- -betal*pi_new[t]*thetalt1*thetalt2
      Km[9] &amp;lt;- gammal*thetalt2
      Km[5] &amp;lt;- -Km[1]-Km[9]
      
      Km[2] &amp;lt;- -betal*pi_new[t]*(thetalt1+0.5*Km[1])*(thetalt2+0.5*Km[5])
      Km[10] &amp;lt;- gammal*(thetalt2+0.5*Km[5])
      Km[6] &amp;lt;- -Km[2]-Km[10]
      
      Km[3] &amp;lt;- -betal*pi_new[t]*(thetalt1+0.5*Km[2])*(thetalt2+0.5*Km[6])
      Km[11] &amp;lt;- gammal*(thetalt2+0.5*Km[6])
      Km[7] &amp;lt;- -Km[3]-Km[11]
      
      Km[4] &amp;lt;- -betal*pi_new[t]*(thetalt1+Km[3])*(thetalt2+Km[7])
      Km[12] &amp;lt;- gammal*(thetalt2+Km[7])
      Km[8] &amp;lt;- -Km[4]-Km[12]
      
      alpha_post[1] &amp;lt;- thetalt1+(Km[1]+2*Km[2]+2*Km[3]+Km[4])/6
      alpha_post[2] &amp;lt;- thetalt2+(Km[5]+2*Km[6]+2*Km[7]+Km[8])/6
      alpha_post[3] &amp;lt;- thetalt3+(Km[9]+2*Km[10]+2*Km[11]+Km[12])/6
      
      thetalt_tmp &amp;lt;- rdirichlet(1, kt* abs(alpha_post))
      thetalt1 &amp;lt;- theta_post[l,t,1] &amp;lt;- thetalt_tmp[1]
      thetalt2 &amp;lt;- theta_post[l,t,2] &amp;lt;- thetalt_tmp[2]
      thetalt3 &amp;lt;- theta_post[l,t,3] &amp;lt;- thetalt_tmp[3]
      
      I_post[l,t] &amp;lt;- rbeta(1,lambdaIl*thetalt2,lambdaIl*(1-thetalt2))
      R_post[l,t] &amp;lt;- rbeta(1,lambdaRl*thetalt3,lambdaRl*(1-thetalt3))
      
    }
    
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The outer loop runs for each of the MCMC chains generated by &lt;code&gt;mcmc_output&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If any of $\beta, \gamma, \theta^S,\theta^I, \theta^R$ turns out to be less than $0$, the chain is stopped and is not proceeded further.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In the inner loop, for each new timepoint, we perform the &lt;a href=&#34;https://en.wikipedia.org/wiki/Runge%E2%80%93Kutta_methods&#34;&gt;Runge Kutta methods&lt;/a&gt; of numerically solving the differential equations,&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;At the end of the loop, we have all the estimates for proportion of Infected and Removed, as well as the three latent proportion parameters $\theta$ which accords with the underlying mathematical model of SIR.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Here, &lt;code&gt;pi_new[t] = pi[T_obs + t]&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;derivation-of-3-important-dates&#34;&gt;Derivation of 3 important dates&lt;/h3&gt;
&lt;p&gt;Associated with the estimation of eSIR model, there are three important dates, which we should output from our algorithm.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The date when $\dfrac{d^2 \theta^I_t}{dt^2} = 0$. This date is the time, when the rate of change in the proportion of infected people starts to be decreasing, so we are in a hopeful scenario that the number of new infected cases is going to be decreasing over time.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The date when $\dfrac{d \theta^I_t}{dt} = 0$, i.e. the date from when the number of new recovered cases starts to exceed the number of new infected cases. From this time onwards, the epidemic nature of the disease vanishes.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The date when $\theta^I_t = 0$. However, it is impossible to have this proportion equal to $0$, in finite times. Therefore, we shall be looking for a date, when $\theta^I_t &amp;lt; \epsilon$, where $\epsilon$ is a very small quantity, which can be treated readily at any time.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;To simplify the calculation of derivative, we track the quantity $(\beta \pi(t) \theta^S_t\theta^I_t - \gamma \theta^I_t)$ over time, which is equal to the derivative due to SIR modelling.&lt;/p&gt;
&lt;p&gt;The following picture taken from the &lt;a href=&#34;https://www.medrxiv.org/content/10.1101/2020.02.29.20029421v1.full.pdf&#34;&gt;paper&lt;/a&gt; by Wang et al. shows the concept clearly.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./deriv.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;theta_diff_pre &amp;lt;- theta_pre[, 1:T_obs, 2] * sweep(beta_pre %*% t(pi[1:T_obs]) * theta_pre[, 1:T_obs, 1], MARGIN = 1, STATS = gamma_pre)
theta_diff_post &amp;lt;- theta_post[, , 2] * sweep(beta_pre %*% t(pi[(T_obs+1):(T_obs+T_new)]) * theta_post[, , 1], MARGIN = 1, STATS = gamma_pre)
theta_diff &amp;lt;- cbind(theta_diff_pre, theta_diff_post)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, we find the maximum of each row of &lt;code&gt;theta_diff&lt;/code&gt; and locate the timepoints, where &lt;code&gt;theta_diff&lt;/code&gt; is changing its signs. They should give up the required first and second important dates.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;first_dates &amp;lt;- apply(theta_diff, 1, which.max)
second_dates &amp;lt;- apply(theta_diff, 1, function(x) { length(x) + 1 - which(cumprod(rev(x &amp;lt;= 0)) == 0)[1] } )    # the first time it becomes negative and stays negative throughout
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, that we have the dates for each chain, let us take the mean, median, and quantiles, which would give us estimates and confidence intervals for such dates.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;conf.quant &amp;lt;- c(conf.level/2, 0.5, 1-conf.level/2)    # conf.level is the confidence coefficients for the confidence interval
first_date_summary &amp;lt;- c( mean(first_dates, na.rm = T), quantile(first_dates, probs = conf.quant, na.rm = T) )
second_date_summary &amp;lt;- c( mean(second_dates, na.rm = T), quantile(second_dates, probs = conf.quant, na.rm = T) )
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;summarising-the-forecast-outputs&#34;&gt;Summarising the forecast outputs&lt;/h3&gt;
&lt;p&gt;Once we have perform forecasting for each and every chain of the MCMC samples, we can aggregated them to obtain the mean, median, and quantiles, which would give us estimates for the proportion of people in state infected and removed, as well as the confidence interval for those estimates.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# till the observed time points
thetaI_band &amp;lt;- t(apply(theta_pre[,-1,2] , 2, quantile, probs=conf.quant, na.rm=T))   
thetaR_band&amp;lt;- t(apply(theta_pre[,-1,3] , 2, quantile, probs=conf.quant, na.rm=T))
thetaI_mean &amp;lt;- colMeans(theta_pre[, -1, 2], na.rm = T)
thetaR_mean &amp;lt;- colMeans(theta_pre[, -1, 3], na.rm = T)

# for the new time points
YI_band &amp;lt;- t(apply(I_post , 2, quantile, probs=conf.quant, na.rm=T))   
YR_band&amp;lt;- t(apply(R_post , 2, quantile, probs=conf.quant, na.rm=T))
YI_mean &amp;lt;- colMeans(I_post, na.rm = T)
YR_mean &amp;lt;- colMeans(R_post, na.rm = T)

# combine into a data frame
infected.dat &amp;lt;- data.frame( rbind( cbind(thetaI_mean, thetaI_band, rep(&amp;quot;pre&amp;quot;, T_obs) ), cbind(YI_mean, YI_band, rep(&amp;quot;post&amp;quot;, T_new) ) ) )
removed.dat &amp;lt;- data.frame( rbind( cbind(thetaR_mean, thetaR_band, rep(&amp;quot;pre&amp;quot;, T_obs) ), cbind(YR_mean, YR_band, rep(&amp;quot;post&amp;quot;, T_new) ) ) )

colnames(infected.dat) &amp;lt;- c(&amp;quot;mean&amp;quot;, &amp;quot;lower&amp;quot;, &amp;quot;median&amp;quot;, &amp;quot;upper&amp;quot;)
colnames(removed.dat) &amp;lt;- c(&amp;quot;mean&amp;quot;, &amp;quot;lower&amp;quot;, &amp;quot;median&amp;quot;, &amp;quot;upper&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then, we can return a list comprising of these two datasets, as well as the summary corresponding to the first and second date obtained earlier. This whole piece of code, is compressed into a function called &lt;code&gt;forecast.SIR&lt;/code&gt;, which we shall call later.&lt;/p&gt;
&lt;h1 id=&#34;checking-performance-of-esir&#34;&gt;Checking Performance of eSIR&lt;/h1&gt;
&lt;p&gt;Now, we shall be using the data for &lt;code&gt;Italy&lt;/code&gt;, in order to figure out how our &lt;code&gt;eSIR&lt;/code&gt; model performs for this data.&lt;/p&gt;
&lt;h2 id=&#34;performance-for-italy&#34;&gt;Performance for Italy&lt;/h2&gt;
&lt;p&gt;According to &lt;a href=&#34;https://www.worldometers.info/world-population/italy-population/&#34;&gt;Worldometers&lt;/a&gt; sources, the projected population for Italy is about 6 crores. Based on that, we compute the observed proportion of the infected and removed (including deaths and recovered), and fit the eSIR model. The following code calls the &lt;code&gt;do.MCMC&lt;/code&gt; function and performs the MCMC fitting. Here, we use 4 weeks of data, of the available 5 weeks of data, and we shall try to forecast for the last week, to see how the model performed.&lt;/p&gt;
&lt;p&gt;Also, the $\pi(t)$ function choosen for Italy is as follows;&lt;/p&gt;
&lt;p&gt;$$\pi(t) = \begin{cases}
1 &amp;amp; \text{ if } t &amp;lt; \text{4th March, 2020}\\\&lt;br&gt;
0.25 &amp;amp; \text{ if } t &amp;gt; \text{9th March, 2020}\\\&lt;br&gt;
0.5 &amp;amp; \text{ otherwise }\\\&lt;br&gt;
\end{cases}$$&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;subdat &amp;lt;- dat %&amp;gt;% mutate(Removed = Deaths + Recovered) %&amp;gt;% filter(Country == &amp;quot;Italy&amp;quot; &amp;amp; Removed &amp;gt; 0)

N &amp;lt;- 60550075
R &amp;lt;- subdat$Removed / N
I &amp;lt;- subdat$Confirmed/N - R
pi0 &amp;lt;- ifelse(subdat$Date &amp;lt; as.Date(&#39;2020-03-04&#39;), 1, 
              ifelse(subdat$Date &amp;gt; as.Date(&#39;2020-03-09&#39;), 0.25, 0.5))

init.params &amp;lt;- list(R0 = 3.15, R0_sd = 1, gamma0 = 0.0117, gamma0_sd = 0.1)
control.params &amp;lt;- list(nchain=4, nadapt=1e4, ndraw=5e2, thin=10, nburnin=2e2)
control.params$mclen &amp;lt;- round(control.params$ndraw / control.params$thin) * control.params$nchain 

mcmc_samples &amp;lt;- do.MCMC(I[1:28], R[1:28], pi0[1:28], init.params, control.params)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You should see something like this, which tells you that the JAGS code for MCMC is running properly.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 56
   Unobserved stochastic nodes: 35
   Total graph size: 1591

Initializing model
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As we see from the following plot, the predictions for the last week is underestimating the true proportions. However, the observed proportions lie within the bound of $95%$ confidence band.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;preds &amp;lt;- forecast.SIR(7, 28, mcmc_samples, pi = pi0, control.params = control.params, start.date = &amp;quot;2020-02-21&amp;quot;)
ggplot(preds$infected, aes(x = date)) + 
    geom_ribbon(aes(ymin = lower, ymax = upper, fill = phase), alpha = 0.25) +
    geom_line(aes(y = mean, color = phase), size = 1) +
    labs(x = &amp;quot;Date&amp;quot;, y = &amp;quot;P(Infected)&amp;quot;) +
    geom_point(data = subdat, aes(x = Date, y = (Confirmed - Removed)/N), color = &amp;quot;black&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./unnamed-chunk-20-1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;However, if we assume that, the Italy government maintains the current lockdown indefinitely, then $\pi(t) = 0.25$ will continue to remain. In such case, the important dates (as mentioned above) for change in the rate of newly infected can be obtained, as shown in the following plot.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;pi0 &amp;lt;- c(pi0, rep(0.25, 200))
preds &amp;lt;- forecast.SIR(7+200, 28, mcmc_samples, pi = pi0, control.params = control.params, start.date = &amp;quot;2020-02-21&amp;quot;)
ggplot(preds$infected, aes(x = date)) + 
    geom_ribbon(aes(ymin = lower, ymax = upper, fill = phase), alpha = 0.25) +
    geom_line(aes(y = mean, color = phase), size = 1) +
    geom_vline(xintercept = preds$first.date[1], color = &amp;quot;brown&amp;quot;) + 
    geom_vline(xintercept = preds$second.date[1], color = &amp;quot;blue4&amp;quot;) +
    labs(x = &amp;quot;Date&amp;quot;, y = &amp;quot;P(Infected)&amp;quot;) +
    geom_point(data = subdat, aes(x = Date, y = (Confirmed - Removed)/N), color = &amp;quot;black&amp;quot;) +
    geom_text(x = preds$first.date[1] - 1, y = 0, label = format(preds$first.date[1], &amp;quot;%b %d&amp;quot;), size = 4 ) +
    geom_text(x = preds$second.date[1] - 1, y = 0, label = format(preds$second.date[1], &amp;quot;%b %d&amp;quot;), size = 4 )
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./unnamed-chunk-21-1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Therefore, in Italy, at about June 22, we should see decreasing increments of newly infected persons, and from August 1 onwards, the proportion of infected people should decline.&lt;/p&gt;
&lt;h2 id=&#34;estimation-for-india&#34;&gt;Estimation for India&lt;/h2&gt;
&lt;p&gt;However, our main concern is to find out the situation of India based on this eSIR modelling. Here, we shall use the $\pi(t)$ function as follows, as per various decision taken by the Government, like restriction on international flights, Janta Curfew and full scale lockdowns etc.&lt;/p&gt;
&lt;p&gt;$$\pi(t) = \begin{cases}
1 &amp;amp; \text{ if } t &amp;lt; \text{15th March, 2020}\\\&lt;br&gt;
0.95 &amp;amp; \text{ if } \text{15th March, 2020} &amp;lt; t &amp;lt; \text{19th March, 2020}\\\&lt;br&gt;
0.9 &amp;amp; \text{ if } \text{19th March, 2020} &amp;lt; t &amp;lt; \text{22th March, 2020}\\\&lt;br&gt;
0.5 &amp;amp; \text{ if } \text{22th March, 2020} &amp;lt; t &amp;lt; \text{25th March, 2020}\\\&lt;br&gt;
0.1 &amp;amp; \text{ if } t &amp;gt; \text{25th March, 2020}\\\&lt;br&gt;
\end{cases}$$&lt;/p&gt;
&lt;p&gt;Also, note that in India, many places are rural in nature, while most of the urban population and neighbourhood areas are more susceptible to get the disease than others, due to availablity of metro cities and international airports. So, rather than using the whole population size i.e. $131$ crores as $N$, we shall use about $350$ lakhs as the adjusted population size.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;subdat &amp;lt;- dat %&amp;gt;% mutate(Removed = Deaths + Recovered, Infected = Confirmed - Removed) %&amp;gt;%
    filter(Country == &amp;quot;India&amp;quot; &amp;amp; Removed &amp;gt; 0 &amp;amp; Infected &amp;gt; 0)

N &amp;lt;- 350e5   # adjusted population for metro cities and neighbourhood areas

R &amp;lt;- subdat$Removed / N
I &amp;lt;- subdat$Infected/N

pi0 &amp;lt;- ifelse(subdat$Date &amp;lt; as.Date(&#39;2020-03-15&#39;), 1, 
              ifelse(subdat$Date &amp;lt; as.Date(&#39;2020-03-19&#39;), 0.9, 
                     ifelse(subdat$Date &amp;lt; as.Date(&#39;2020-03-22&#39;), 0.8, 
                            ifelse(subdat$Date &amp;lt; as.Date(&#39;2020-03-25&#39;), 0.5, 0.1)) ))

init.params &amp;lt;- list(R0 = 12.48, R0_sd = 1, gamma0 = 0.117, gamma0_sd = 1)
control.params &amp;lt;- list(nchain=4, nadapt=1e4, ndraw=5e2, thin=5, nburnin=2e2)
control.params$mclen &amp;lt;- round(control.params$ndraw / control.params$thin) * control.params$nchain 

mcmc_samples &amp;lt;- do.MCMC(I, R, pi0, init.params, control.params)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And finally, we perform the prediction till the end of the lockdown, i.e. till $14$-th April, to see the effect of quaranting.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;pi1 &amp;lt;- c(pi0, rep(0.1, 19))   # from 27th March, it is 19 days of lockdown left 
preds &amp;lt;- forecast.SIR(19, 25, mcmc_samples, pi = pi1, control.params = control.params, start.date = &amp;quot;2020-03-02&amp;quot;)
ggplot(preds$infected, aes(x = date)) + 
    geom_ribbon(aes(ymin = lower, ymax = upper, fill = phase), alpha = 0.25) +
    geom_line(aes(y = mean, color = phase), size = 1) +
    labs(x = &amp;quot;Date&amp;quot;, y = &amp;quot;P(Infected)&amp;quot;) +
    geom_point(data = subdat, aes(x = Date, y = Infected/N), color = &amp;quot;black&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./unnamed-chunk-23-1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Although it seems that the mean proportion is overestimated during the ovserved period, however the effect of quanting seems to work to a moderate extent, as the estimated proportion stays more or less at the same level. The exact count of the infected people at the end of lockdown, provided that it is maintained properly, should be about $1317$ many infected persons, and about $2114$ confirmed cases of COVID-19.&lt;/p&gt;
&lt;p&gt;Similar to Italy, if we extend its forecast for some more days, and keep the same level of quaranting, the model predictions are given in the following plot.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;pi2 &amp;lt;- c(pi0, rep(0.1, 200)) 
preds &amp;lt;- forecast.SIR(200, 25, mcmc_samples, pi = pi2, control.params = control.params, start.date = &amp;quot;2020-03-02&amp;quot;)
ggplot(preds$infected, aes(x = date)) + 
    geom_ribbon(aes(ymin = lower, ymax = upper, fill = phase), alpha = 0.25) +
    geom_line(aes(y = mean, color = phase), size = 1) +
    geom_vline(xintercept = preds$first.date[1], color = &amp;quot;brown&amp;quot;, size = 1, linetype = &amp;quot;dashed&amp;quot;) + 
    geom_vline(xintercept = preds$second.date[1], color = &amp;quot;blue4&amp;quot;, size = 1, linetype = &amp;quot;dashed&amp;quot;) +
    labs(x = &amp;quot;Date&amp;quot;, y = &amp;quot;P(Infected)&amp;quot;) +
    geom_point(data = subdat, aes(x = Date, y = (Confirmed - Removed)/N), color = &amp;quot;black&amp;quot;) +
    geom_text(x = preds$first.date[1] - 7, y = 2e-4, label = format(preds$first.date[1], &amp;quot;%b %d&amp;quot;), size = 4 ) +
    geom_text(x = preds$second.date[1] + 7, y = 3e-4, label = format(preds$second.date[1], &amp;quot;%b %d&amp;quot;), size = 4 )
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./unnamed-chunk-25-1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Therefore, as it seems, if we keep the lockdown (as it is now), based on the data, it might take till October to have the proportion of infected people becoming insignificant, provided we keep the same level of quanranting effect. However, from March 17, we should see a decrease in the rate of increment in the number of infected, and from March 29 onwards, we should be at a position from where the number of newly infected persons per day starts to decrease.&lt;/p&gt;
&lt;p&gt;Since, it is very economically and physically dissatisfying to be in a lockdown (or state of home quarantine till October, where Durga Puja festival is going to occur), we might want to go outside. In that case, assuming $\pi(t)$ increases to $0.5$, which is indeed less than 1, due to our increasing awareness of the scenario, then, the predicted situation would look like this.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;pi3 &amp;lt;- c(pi0, rep(0.1, 19), rep(0.5, 2 * 365)) 
preds &amp;lt;- forecast.SIR(2 * 365 + 19, 25, mcmc_samples, pi = pi3, control.params = control.params, start.date = &amp;quot;2020-03-02&amp;quot;)
preds$infected$upper_new &amp;lt;- pmin(preds$infected$upper, 0.05)   # just for visual purpose
ggplot(preds$infected, aes(x = date)) + 
    geom_ribbon(aes(ymin = lower, ymax = upper_new, fill = phase), alpha = 0.25) +
    geom_line(aes(y = mean, color = phase), size = 1) +
    geom_vline(xintercept = preds$first.date[1], color = &amp;quot;brown&amp;quot;, size = 1, linetype = &amp;quot;dashed&amp;quot;) + 
    geom_vline(xintercept = preds$second.date[1], color = &amp;quot;blue4&amp;quot;, size = 1, linetype = &amp;quot;dashed&amp;quot;) +
    labs(x = &amp;quot;Date&amp;quot;, y = &amp;quot;P(Infected)&amp;quot;) +
    geom_point(data = subdat, aes(x = Date, y = (Confirmed - Removed)/N), color = &amp;quot;black&amp;quot;) +
    geom_text(x = preds$first.date[1] - 7, y = 2e-4, label = format(preds$first.date[1], &amp;quot;%b %d&amp;quot;), size = 4 ) +
    geom_text(x = preds$second.date[1] + 7, y = 3e-4, label = format(preds$second.date[1], &amp;quot;%b %d&amp;quot;), size = 4 )
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./unnamed-chunk-26-1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;This scenario would be very severe for us, since it would affect about $4%$ of the urban population, on about June 13, and then it would start to decrease gradually. However, it would take almost 2 years, to make this epidemic insignificant, provided there will be no generally accepted antiviral medicine for COVID-19 till then.&lt;/p&gt;
&lt;p&gt;Hence, we must avoid such situation at all costs, and to counter it, we must stay home, at a shelter in place home quaranting atmosphere.&lt;/p&gt;
&lt;h1 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;This &lt;strong&gt;eSIR model is not perfect.&lt;/strong&gt; No statistical model is. But the main idea and examples that we are seeing currently all over the world, should give us a hint about what is to come.&lt;/p&gt;
&lt;p&gt;There are several backdrops in &lt;strong&gt;eSIR&lt;/strong&gt; model.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;It does not talk about underreporting. When you are in a place like India, underreporting is a major issue, as there might be some people who are affected by coronavirus, but lightly takes their symptoms as seasonal cold.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In the basis of SIR model, we assume the existence of only 3 states. To incorporate the effect of quaranting, we only considering the people in Infected state. However, there might be people who are infected, and can spread the disease, yet they do not have the symptoms, and hence does not fall under the effect of quaranting.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We shall try to deal with these shortcomings in our next post, where we shall consider building more out of this particular model.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;WHO Guidelines to STAY SAFE:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The best way to prevent and slow down transmission is be well informed about the COVID-19 virus, the disease it causes and how it spreads.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Wash your hands frequently with an alcohol based rub or soap.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Maintain social distancing.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Avoid touching eyes, nose and mouth.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Practice respiratory hygiene.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If you have fever, cough and difficulty breathing, seek medical care early.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Stay informed and follow advice given by your healthcare provider.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Protect yourselves and protect others.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Signing Off&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;$\qquad &amp;mdash;$ Soham Bonnerjee &amp;amp; Subhrajyoty Roy&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Stay home, Stay safe, Keep safe your friends, families and neighbours.&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>SIR Modelling of COVID-19 Pandemic situation</title>
      <link>/post/covid19-project/</link>
      <pubDate>Wed, 25 Mar 2020 00:00:00 +0000</pubDate>
      <guid>/post/covid19-project/</guid>
      <description>&lt;h1 id=&#34;the-current-global-scenario&#34;&gt;The Current Global Scenario&lt;/h1&gt;
&lt;p&gt;At the end of December 2019, a cluster of an unknown pneumonia like cases were reported in Wuhan, a city in the Hubei province, China. They quickly identified that the source of the infection was a novel coronavirus belonging to the coronavirus family, which includes the virus related to the outbreaks of  Severe Acute Respiratory Syndrome (SARS) from 2002-2004 and Middle East Respiratory Syndrome (MERS) in 2012. It  spread through and outside of Wuhan, resulting in an rapidly escalating and deadly contagious epidemic throughout China, followed by an increasing number of cases in other countries throughout the world.&lt;br&gt;
On January 30, the WHO declared coronavirus a global emergency  as the death toll in China jumped to 170, with 7,711 cases reported in the country, where the virus had spread to all 31 provinces.  In mid-February WHO announced that the new coronavirus would be called &amp;ldquo;COVID-19&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;China&#39;s bold approach to contain the rapid spread of this new respiratory pathogen  by massive lockdowns and electronic surveillance measures has changed the changed the course of the epidemic . The number of new infections reported in China has been declining gradually. With over 422,915 reported cases and more than 18,543 recorded deaths worldwide , the outbreak of COVID-19 has surpassed the toll of the 2002-2003 SARS outbreak, which also originated in China and is expected to continue to increase.  Although the infection originated in China, now the epicenter of the pandemic is Europe, which now has more cases reported each day than China did at the height of its outbreak.  In Italy alone the COVID-19 has infected more than 69,000 people and killed at least 6,800. There is an increasing number of cases in several EU/EEA countries without epidemiological links to explain the source of transmission. The speed with which COVID-19 can cause nationally incapacitating epidemics once transmission within the community is established indicates that it is likely that in a few weeks or even days, similar situations to those seen in China and Italy may be seen in other EU/EEA countries or the UK, as more countries report evidence of community transmission.
The COVID-19 virus spreads primarily through droplets of saliva or discharge from the nose when an infected person coughs or sneezes.  At the time of this writing, there are no specific vaccines or treatments for COVID-19 which is generally accepted.&lt;/p&gt;
&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;This is a post to give a basic understanding of statistical modelling of epidemiology. In past few days of Shelter-in-place lockdown situation in Kolkata (and throughout the whole India from today onwards), me and one of my friend &lt;a href=&#34;https://subroy13.github.io/&#34;&gt;Subhrajyoty Roy&lt;/a&gt; (we were attending the same college before lockdown to purse Masters degree in Statistics), was reading about different epidemiological models available in the literature and using it to generate projections for the number of infected people in India.&lt;/p&gt;
&lt;p&gt;In this post, we shall explore the performance of deterministic SIR model which to be fitted using a least squares procedure. Then, we shall use it to generate projections for the epidemic situation in India, till the end of this lockdown, which is currently annouced to be remain till April 14, 2020, about 3 weeks from today.&lt;/p&gt;
&lt;h1 id=&#34;exploratory-analysis&#34;&gt;Exploratory Analysis&lt;/h1&gt;
&lt;p&gt;Before proceeding with introducing the SIR model, let us first read the data into &lt;code&gt;R&lt;/code&gt; (which is what we are going to use through out), and perform some exploratory analysis. We shall be using the &lt;a href=&#34;https://www.tidyverse.org/&#34;&gt;tidyverse&lt;/a&gt; library, which is a collection of some very useful packages for data proprocessing and exploratory analysis.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(readr)
library(dplyr)
library(tidyr)
library(lubridate)
library(ggplot2)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For the related coronavirus, there are may different sources available. Many international organizations like WHO (World Health Organization), ECDC (European Centre for Disease Prevention and Control) and many national governments are releasing day to day basis publicly available data. As well as different news agencies are also collecting and compileing data from the hospitals and different other sources on a regular basis. John Hopkins University (JHU) CSSE department has also released a dataset compiled from the collection of these sources in a github repository &lt;a href=&#34;https://github.com/CSSEGISandData/COVID-19&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The datasets are being updated on a daily basis. We shall use this data provided by &lt;a href=&#34;https://github.com/CSSEGISandData/COVID-19&#34;&gt;JHU CSSE&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;confirmed.dat &amp;lt;- read_csv(&#39;./datasets/time_series_19-covid-Confirmed.csv&#39;)
deaths.dat &amp;lt;- read_csv(&#39;./datasets/time_series_19-covid-Deaths.csv&#39;)
recovered.dat &amp;lt;- read_csv(&#39;./datasets/time_series_19-covid-Recovered.csv&#39;)

confirmed.dat &amp;lt;- confirmed.dat %&amp;gt;%
    rename( State = `Province/State`, Country = `Country/Region` ) %&amp;gt;% 
    gather(key = &amp;quot;Date&amp;quot;, value = &amp;quot;Confirmed&amp;quot;, -c(1:4) ) %&amp;gt;%
    mutate(Date = mdy(Date))
    

deaths.dat &amp;lt;- deaths.dat %&amp;gt;%
    rename( State = `Province/State`, Country = `Country/Region` ) %&amp;gt;% 
    gather(key = &amp;quot;Date&amp;quot;, value = &amp;quot;Deaths&amp;quot;, -c(1:4) ) %&amp;gt;% 
    mutate(Date = mdy(Date))

recovered.dat &amp;lt;- recovered.dat %&amp;gt;%
    rename( State = `Province/State`, Country = `Country/Region` ) %&amp;gt;% 
    gather(key = &amp;quot;Date&amp;quot;, value = &amp;quot;Recovered&amp;quot;, -c(1:4) ) %&amp;gt;%
    mutate(Date = mdy(Date))


# merge all of them together
dat &amp;lt;- Reduce(merge, list(confirmed.dat, deaths.dat, recovered.dat))
dat &amp;lt;- as_tibble(dat)

knitr::kable(head(dat, 5))
&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;State&lt;/th&gt;
&lt;th&gt;Country&lt;/th&gt;
&lt;th&gt;Lat&lt;/th&gt;
&lt;th&gt;Long&lt;/th&gt;
&lt;th&gt;Date&lt;/th&gt;
&lt;th&gt;Confirmed&lt;/th&gt;
&lt;th&gt;Deaths&lt;/th&gt;
&lt;th&gt;Recovered&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Adams, IN&lt;/td&gt;
&lt;td&gt;US&lt;/td&gt;
&lt;td&gt;39.8522&lt;/td&gt;
&lt;td&gt;-77.2865&lt;/td&gt;
&lt;td&gt;2020-01-22&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Adams, IN&lt;/td&gt;
&lt;td&gt;US&lt;/td&gt;
&lt;td&gt;39.8522&lt;/td&gt;
&lt;td&gt;-77.2865&lt;/td&gt;
&lt;td&gt;2020-01-23&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Adams, IN&lt;/td&gt;
&lt;td&gt;US&lt;/td&gt;
&lt;td&gt;39.8522&lt;/td&gt;
&lt;td&gt;-77.2865&lt;/td&gt;
&lt;td&gt;2020-01-24&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Adams, IN&lt;/td&gt;
&lt;td&gt;US&lt;/td&gt;
&lt;td&gt;39.8522&lt;/td&gt;
&lt;td&gt;-77.2865&lt;/td&gt;
&lt;td&gt;2020-01-25&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Adams, IN&lt;/td&gt;
&lt;td&gt;US&lt;/td&gt;
&lt;td&gt;39.8522&lt;/td&gt;
&lt;td&gt;-77.2865&lt;/td&gt;
&lt;td&gt;2020-01-26&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Now we shall try to see how the total number of Confirmed, deaths and recovered people changed across the globe.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;temp &amp;lt;- dat %&amp;gt;% group_by(Date) %&amp;gt;% 
    summarise(Confirmed = sum(Confirmed), Deaths = sum(Deaths), Recovered = sum(Recovered)) %&amp;gt;%
    gather(key = &amp;quot;Variable&amp;quot;, value = &amp;quot;Count&amp;quot;, -Date)

ggplot(temp, aes(x = Date, y = Count, color = Variable)) + geom_line(size = 1)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./unnamed-chunk-6-1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;The situation is very severe, as the current trend in exponentially increasing in terms of confirmed cases, and the growth rate of recovered is sufficiently slow. If we particular focus on the situation of India, (after 1st March, 2020),&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;unnamed-chunk-7-1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;As of now, there are very less number of recoveries, some deaths, and a lot of (about 400) affected people. We have also compiled how these changes occurs spatially in different countries. They are shown below.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./confirmed-1.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./deaths-1.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;sir-model-description&#34;&gt;SIR Model Description&lt;/h1&gt;
&lt;p&gt;The SIR model is one of the compartmental models in epidemiology which is used to mathematically model the spread of an infectious disease. This model was firstly introduced by William Ogilvy Kermack and A. G. McKendrick, and named as &lt;strong&gt;Kermack-McKendrick Model.&lt;/strong&gt; However, with time, this model has obtained several variants, each being better than the one before.&lt;/p&gt;
&lt;p&gt;SIR modelling starts with defining 3 different compartments, of states in which a person can be. The states are as follows:&lt;/p&gt;
&lt;div class=&#34;mermaid&#34;&gt;
graph LR;
    S(Susceptible) --&gt; I(Infected);
    I(Infected) --&gt; R(Recovered / Removed);
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Susceptibles&lt;/strong&gt; are the general population, who is susceptible to get the disease from an infectious person. &lt;strong&gt;Infected&lt;/strong&gt; state reperesents the persons who have the symptoms of the infection and is able to spread it. And finally, &lt;strong&gt;Recovered&lt;/strong&gt; or &lt;strong&gt;Removed&lt;/strong&gt; is the state when a person is recovered from the disease and gain immunity to it, or is dead. Let, $Y_t^S, Y_t^I, Y_t^R$ dentoes the number of people in these states respectively at the time $t$. The corresponding proportions are denoted by $\theta_t^S, \theta_t^I$ and $\theta_t^R$, where the proportion is defined as the number of people in a state divided by the total number of people, i.e. the population count. Note that, since these three states are assumed to be exhaustive, hence $Y_t^S + Y_t^I + Y_t^R = N$, where $N$ is the total population of the particular region under study.&lt;/p&gt;
&lt;p&gt;The mathematical relations between these quantities are defined as follows:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\dfrac{d\theta_t^S}{dt} &amp;amp; = -\beta \theta_t^S \theta_t^I\\\&lt;br&gt;
&amp;amp; \\\&lt;br&gt;
\dfrac{d\theta_t^I}{dt} &amp;amp; = \beta \theta_t^S \theta_t^I - \gamma \theta_t^I\\\&lt;br&gt;
&amp;amp; \\\&lt;br&gt;
\dfrac{d\theta_t^R}{dt} &amp;amp; = \gamma \theta_t^I\\\&lt;br&gt;
\end{align}
$$&lt;/p&gt;
&lt;p&gt;Note that, since $Y_t^S + Y_t^I + Y_t^R = N$, we have $\theta_t^S + \theta_t^I + \theta_t^R = 1$, which is constant. Hence, we must have,&lt;/p&gt;
&lt;p&gt;$$ \dfrac{d\theta_t^S}{dt} + \dfrac{d\theta_t^I}{dt} + \dfrac{d\theta_t^R}{dt} = 0 $$&lt;/p&gt;
&lt;p&gt;which is satisfied by the mathematical formulation. In this, $\beta, \gamma$ are unknown parameters which is to be estimated from the data.&lt;/p&gt;
&lt;p&gt;These mathematical equations did not drop from the sky. Let us understand how these mathematical formula emerges from an intuitive points of view.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;We consider the third equation first. It models the change in the number of recovered people. Now, the change in the number (or proportion) of recovered people can occur only when an infectious person, gets treatment, which happens with rate $\gamma$, which can be interpreted as the recovery rate of an infectious person. Therefore, it changes by the amount $\gamma \theta_t^I$.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Now we consider the first equation. It models the change in the number of susceptible population. The change in susceptible population occurs, when an infectious person comes in contact with a susceptible person, and the infection spreads. Now, there are $Y_t^I Y_t^S$ many interactions possible, and each interaction would spread the virus with rate $\beta$ say. Considering proportions, we have the change being equal to $-\beta\theta_t^I\theta_t^S$, with the negative sign showing that number of susceptibles can only decrease.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Due to the restriction, $\dfrac{d\theta_t^S}{dt} + \dfrac{d\theta_t^I}{dt} + \dfrac{d\theta_t^R}{dt} = 0$, the choice of $\dfrac{d\theta_t^I}{dt}$ can be justfied from previous points.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;A very important measure in this model is the quantity;&lt;/p&gt;
&lt;p&gt;$$R_0 = \dfrac{\beta}{\gamma}$$&lt;/p&gt;
&lt;p&gt;This basically interprets as the average number of people an infectious person infects before recovering or dying. So, if $R_0 &amp;lt; 1$, then an infectious person infects less than one person in average before recovering, which means the infection pandemic will eventually die out. Whereas, if $R_0 &amp;gt; 1$, then an infectious person infects more than one person in average before recovering, hence the number of infected would increase exponentially and eventually all of the population will become infected.&lt;/p&gt;
&lt;h1 id=&#34;estimation-of-sir-model&#34;&gt;Estimation of SIR Model&lt;/h1&gt;
&lt;p&gt;There are two possible ways of estimation of the parameters of an SIR model.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;A deterministic estimation.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A stochastic estimation.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;A deterministic estimation does not require any other assumptions on the model parameters, as well as the data. It basically works simply on the basis of solution to the above differential equations. However, a stochastic estimation requires specifications of the distributional assumptions on the data, as well as model parameters. In this post, we are going to use only a deterministic setup of the model as explained in the mathematical formulation, nothing more.&lt;/p&gt;
&lt;p&gt;For this reason, we shall use &lt;a href=&#34;https://en.wikipedia.org/wiki/Runge%E2%80%93Kutta_methods&#34;&gt;Runge Kutta methods&lt;/a&gt; of numerically solving a system of differential equations, under some particular choice of the model parameters $\beta, \gamma$. However, as we solve the differential equations, we shall be able to obtain estimates $\hat{Y}_t^S, \hat{Y}_t^I$ and $\hat{Y}_t^R$. Then, we can use a Least Squares approach to solve this problem, to estimate $\beta, \gamma$ as;&lt;/p&gt;
&lt;p&gt;$$
(\hat{\beta}, \hat{\gamma}) = \min_{\beta, \gamma} \sum_t \left[ \left(Y_t^S - \hat{Y}_t^S\right)^2 + \left(Y_t^I - \hat{Y}_t^I\right)^2 + \left(Y_t^R - \hat{Y}_t^R\right)^2 \right]
$$&lt;/p&gt;
&lt;p&gt;To this end, we write the function &lt;code&gt;pred.SIR&lt;/code&gt; and &lt;code&gt;LS.SIR&lt;/code&gt; which performs the prediction given the initial value and parameters, and computes the value of the objective function written above by tallying it with the observed data.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;pred.SIR &amp;lt;- function(n_time, beta, gamma, init.theta) {
    theta &amp;lt;- matrix(0, nrow = n_time, ncol = 3)
    theta[1, ] &amp;lt;- init.theta / sum(init.theta)
    
    for (t in 2:n_time) {
        # for each time, create the Runge Kutta approximation
        Km &amp;lt;- numeric(12)   # 12 coefficients are needed
        
        # computes coefficients of runge kutta
        Km[1] &amp;lt;- - beta * theta[t-1,1] * theta[t-1,2]
        Km[9] &amp;lt;- gamma * theta[t-1,2]
        Km[5] &amp;lt;- -Km[1]-Km[9]
        
        Km[2] &amp;lt;- - beta * (theta[t-1,1]+ 0.5*Km[1]) * (theta[t-1,2]+0.5*Km[5])
        Km[10] &amp;lt;- gamma*(theta[t-1,2]+0.5*Km[5])
        Km[6] &amp;lt;- -Km[2]-Km[10]
        
        Km[3] &amp;lt;- -beta*(theta[t-1,1]+0.5*Km[2])*(theta[t-1,2]+0.5*Km[6])
        Km[11] &amp;lt;- gamma*(theta[t-1,2]+0.5*Km[6])
        Km[7] &amp;lt;- -Km[3]-Km[11]
      
        Km[4] &amp;lt;- -beta*(theta[t-1,1]+Km[3])*(theta[t-1,2]+Km[7])
        Km[12] &amp;lt;- gamma*(theta[t-1,2]+Km[7])
        Km[8] &amp;lt;- -Km[4]-Km[12]
        
        innov.S &amp;lt;- ( Km[1] + 2 *Km[2] + 2*Km[3] + Km[4])/6
        innov.I &amp;lt;- ( Km[5] + 2 *Km[6] + 2*Km[7] + Km[8])/6
        innov.R &amp;lt;- ( Km[9] + 2 *Km[10] + 2*Km[11] + Km[12])/6
        
        theta[t, ] &amp;lt;- theta[(t-1), ] + c(innov.S, innov.I, innov.R)
        theta[t, ] &amp;lt;- theta[t, ]/sum(theta[t, ])
    }
    
    return(theta)
}
LS.SIR &amp;lt;- function(params, Y) {
    beta &amp;lt;- params[1]
    gamma &amp;lt;- params[2]
    n_time &amp;lt;- nrow(Y)
    N &amp;lt;- sum(Y[1, ])
    
    init.theta &amp;lt;- Y[1, ] / N
    preds &amp;lt;- pred.SIR(n_time, beta, gamma, init.theta)
    
    return( sum((Y - preds * N )^2) ) 
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;performance-of-sir-model&#34;&gt;Performance of SIR model&lt;/h1&gt;
&lt;h2 id=&#34;estimation-for-hong-kong-china&#34;&gt;Estimation for Hong Kong, China&lt;/h2&gt;
&lt;p&gt;We choose the Hong Kong province in China to see how SIR model performs. According to World Bank data, the province Hong Kong is home to about $73.9$ lakhs people. Therefore, we have $N = 73.9\times 10^5$, in our model.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;N &amp;lt;- 73.9e5   # population of Hong Kong
temp  &amp;lt;- dat %&amp;gt;% filter(Country == &amp;quot;China&amp;quot; &amp;amp; State == &amp;quot;Hong Kong&amp;quot;) %&amp;gt;% 
    mutate(Removed = Deaths + Recovered, Susceptible = N - Removed - Confirmed) %&amp;gt;% 
    select(Date, Susceptible, Confirmed, Removed)

knitr::kable(head(temp))
&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Date&lt;/th&gt;
&lt;th&gt;Susceptible&lt;/th&gt;
&lt;th&gt;Confirmed&lt;/th&gt;
&lt;th&gt;Removed&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;2020-01-22&lt;/td&gt;
&lt;td&gt;7390000&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2020-01-23&lt;/td&gt;
&lt;td&gt;7389998&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2020-01-24&lt;/td&gt;
&lt;td&gt;7389998&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2020-01-25&lt;/td&gt;
&lt;td&gt;7389995&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2020-01-26&lt;/td&gt;
&lt;td&gt;7389992&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2020-01-27&lt;/td&gt;
&lt;td&gt;7389992&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;As you can see, the first appearence of Coronavirus in Hong Kong is on 23rd of Janurary, 2020. So, we should use the data from 2nd row onwards to fit into SIR model. We shall be using the data corresponding to $61$ days, i.e. till 23rd of May, 2020. Among this, we shall be training the model using data of first $47$ days, and then we build the prediction for next $14$ days, to see the performance of the fitted model. We shall be using &lt;code&gt;optim&lt;/code&gt; function of &lt;code&gt;R&lt;/code&gt; to optimize our objective function in order to find Least Sqaures estimate.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Y &amp;lt;- as.matrix(temp[2:48, 2:4])
ops &amp;lt;- optim(par = c(1e-2, 1e-5), fn = LS.SIR, method = &amp;quot;BFGS&amp;quot;, Y = Y, control = list(trace = 1))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;initial  value 552556.538521 
iter  10 value 68951.183015
final  value 65031.692121 
converged
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ops$par[1] / ops$par[2]   # R0
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;[1] 3.149289
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that we have the estimated parameters, we can simply generate predictions for last $14$ days, using this &lt;code&gt;pred.SIR&lt;/code&gt; method. Before that, estimate of $R_0$ turns out to be higher than 1, thereby showing the seriousness of the COVID-19 epidemic situation.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# since predictions are proportions, we multiply with the population to get the count estimates

preds &amp;lt;- pred.SIR(14, ops$par[1], ops$par[2], as.matrix(temp[49, 2:4])) * N
pred.dat &amp;lt;- tibble(Date = temp$Date[49:62], Pred.Confirmed = preds[, 2], Pred.Removed = preds[, 3])
pred.dat &amp;lt;- left_join(temp, pred.dat, by = c(&amp;quot;Date&amp;quot; = &amp;quot;Date&amp;quot;))  # create a full dataset containing predicted data as well

ggplot( pred.dat , aes(x = Date) ) +
    geom_line(aes(y = Confirmed), color = &amp;quot;black&amp;quot;, size = 1) +
    geom_line(aes(y = Pred.Confirmed), color = &amp;quot;blue&amp;quot;, size = 1, linetype = &amp;quot;dashed&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./unnamed-chunk-12-1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Therefore, we see that SIR model overestimates the true number by about $75$ people at the last day. Nevertheless, this is simple model, which performs fairly good. However, it would have been nice if we could give a confidence interval around that estimate.&lt;/p&gt;
&lt;h2 id=&#34;performance-for-india&#34;&gt;Performance for India&lt;/h2&gt;
&lt;p&gt;We perform the same exercise for India as well. For India, the population is huge (about $131$ crores) and there is lesser amount of data available, although the first confirmed case of COVID-19 was identified in 30th January, 2020. We have data on $54$ days, among which we shall use all the data before last week, and generate predictions for last week, to visualize its performance.&lt;/p&gt;
&lt;p&gt;The $R_0$ coefficient turns out to be 12.4850813, which is severe as it is a lot more than $1$.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;preds &amp;lt;- pred.SIR(7, ops$par[1], ops$par[2], as.matrix(temp[48, 2:4])) * N
pred.dat &amp;lt;- tibble(Date = temp$Date[48:54], Pred.Confirmed = preds[, 2], Pred.Removed = preds[, 3])
pred.dat &amp;lt;- left_join(temp, pred.dat, by = c(&amp;quot;Date&amp;quot; = &amp;quot;Date&amp;quot;))  # create a full dataset containing predicted data as well

ggplot( pred.dat , aes(x = Date) ) +
    geom_line(aes(y = Confirmed), color = &amp;quot;black&amp;quot;, size = 1) +
    geom_line(aes(y = Pred.Confirmed), color = &amp;quot;blue&amp;quot;, size = 1, linetype = &amp;quot;dashed&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./unnamed-chunk-14-1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Yet in this case, the SIR model does a underestimation in determining the number of confirmed cases by about $100$ cases. Therefore, the seriousness of the pandemic situation is even worse than what is depicted by the number $R_0$, i.e. 12.4850813, it is enitrely possible that the true $R_0$ value is even more at the last week, thereby showing on average an infectious person is infecting more than $12$ persons, which is bad, seriously bad.&lt;/p&gt;
&lt;h2 id=&#34;predictions-till-the-end-of-the-lockdown&#34;&gt;Predictions till the end of the Lockdown&lt;/h2&gt;
&lt;p&gt;To make this prediction, we use all the available datapoints for estimation of the parameters. So, we refit the model.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Y &amp;lt;- as.matrix(temp[, 2:4])
ops &amp;lt;- optim(par = c(1e-2, 1e-5), fn = LS.SIR, method = &amp;quot;BFGS&amp;quot;, Y = Y)

preds &amp;lt;- pred.SIR(22, ops$par[1], ops$par[2], as.matrix(temp[54, 2:4])) * N
pred.dat &amp;lt;- tibble(Date = temp$Date[54] + 1:22, 
                   Pred.Confirmed = preds[, 2], Pred.Removed = preds[, 3])
pred.dat &amp;lt;- full_join(temp, pred.dat, by = c(&amp;quot;Date&amp;quot; = &amp;quot;Date&amp;quot;))  # create a full dataset containing predicted data as well

ggplot( pred.dat , aes(x = Date) ) +
    geom_line(aes(y = Confirmed), color = &amp;quot;black&amp;quot;, size = 1) +
    geom_line(aes(y = Pred.Confirmed), color = &amp;quot;blue&amp;quot;, size = 1, linetype = &amp;quot;dashed&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./unnamed-chunk-15-1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;So, if there was no lockdown happening, the prediction of confirmed cases in India by middle of April would have be about $4000$.&lt;/p&gt;
&lt;p&gt;Note that SIR is the best-case scenario, hence this is an underestimate. Thus without any quarantining intervention, the situation looks grim; But all hope is not lost, for in the next post, we&#39;ll show how different measures of quarantining, including lockdown, help decrease the rate of increase in confirmed cases. Till then stay united, and stay safe. We would get through this hard time.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;WHO Guidelines to STAY SAFE:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The best way to prevent and slow down transmission is be well informed about the COVID-19 virus, the disease it causes and how it spreads.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Wash your hands frequently with an alcohol based rub or soap.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Maintain social distancing.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Avoid touching eyes, nose and mouth.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Practice respiratory hygiene.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If you have fever, cough and difficulty breathing, seek medical care early.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Stay informed and follow advice given by your healthcare provider.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Protect yourselves and protect others.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;dl&gt;
&lt;dt&gt;Signing off&lt;/dt&gt;
&lt;dd&gt;$\qquad &amp;mdash; $ Soham Bonnerjee &amp;amp; Subhrajyoty Roy&lt;/dd&gt;
&lt;/dl&gt;
&lt;blockquote&gt;
&lt;p&gt;Stay informed, Stay home, Stay safe.&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>Multiple Correspondence Analysis</title>
      <link>/project/multiple-correspondence-analysis/</link>
      <pubDate>Fri, 20 Dec 2019 00:00:00 +0000</pubDate>
      <guid>/project/multiple-correspondence-analysis/</guid>
      <description>&lt;p&gt;We first discuss the theories behind Multiple Correspondence Analysis, and then proceed to discuss some applications. Find out more in the PDF and Slides.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Exoplanet Hunting- A Statistical Approach</title>
      <link>/project/exoplanet-hunting/</link>
      <pubDate>Mon, 21 Oct 2019 00:00:00 +0000</pubDate>
      <guid>/project/exoplanet-hunting/</guid>
      <description>&lt;p&gt;An Exoplanet or Extrasolar planet is an earth-like planet outside the Solar System. The Kepler Space Observatory has analyzed 10000 odd &lt;em&gt;Kepler Object of Interests&lt;/em&gt;, and designated them either &lt;em&gt;Exoplanet&lt;/em&gt;, or &lt;em&gt;False Positive&lt;/em&gt;. This designation follows complex mathematical formulae that&#39;s not open to public. We try to emulate Kepler&#39;s analysis using simple statistical tools that also gives us interpretability. Find out more in the slides.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Onset Detection- A New Approach to QBH System</title>
      <link>/publication/journal-article/</link>
      <pubDate>Sun, 01 Sep 2019 00:00:00 +0000</pubDate>
      <guid>/publication/journal-article/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Mapping Human QTL usiing Sib-Pair Data</title>
      <link>/project/haseman-elston-regression/</link>
      <pubDate>Wed, 13 Mar 2019 00:00:00 +0000</pubDate>
      <guid>/project/haseman-elston-regression/</guid>
      <description>&lt;p&gt;Haseman-Elston&#39;s 1970 paper has been a seminal one in the field of Quantitaive Trait Loci (QTL) mapping. In this project, we discuss the methods of the paper, popularly known as &lt;em&gt;Haseman-Elston Regression&lt;/em&gt; in the context of Sibling-Pair data. Find out more in the slides.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>On Mixing Time of  Juggling Markov Chain</title>
      <link>/project/juggling-markov-chain/</link>
      <pubDate>Tue, 31 Jul 2018 00:00:00 +0000</pubDate>
      <guid>/project/juggling-markov-chain/</guid>
      <description>&lt;p&gt;We introduce the Juggling Markov Chain and discuss its various properties, and try to find the order of its Mixing Time. Find more in the pdf.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Privacy Policy</title>
      <link>/privacy/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 +0100</pubDate>
      <guid>/privacy/</guid>
      <description>&lt;p&gt;&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Terms</title>
      <link>/terms/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 +0100</pubDate>
      <guid>/terms/</guid>
      <description>&lt;p&gt;&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
