[{"authors":["admin"],"categories":null,"content":"","date":1585353600,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1585353600,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"","tags":null,"title":"Soham Bonnerjee","type":"authors"},{"authors":["Soham Bonnerjee","Subhrajyoty Roy"],"categories":null,"content":"Current Scenario in INDIA Taking cue from global powerhouses failing catastrophically to contain the onslaught on life that's been lunched by Covid-19, Prime Minister of India Shri Narendra Modi issued instructions for a nationwide Lockdown starting from 25 March'20 to 14 April'20, wth possible plans for further extension. The decision have been welcomed and lauded by various researchers and scientists alike, esopecially after countries like USA and Italy acted too late to a possibly aggravated situation. But why this praise? In this post, we'll find out how lockdown and other forms of quarantining helps contain the infection.\nBut before that, a gentle reminder of what we are up against: till date, Covid-19 virus has affected $722$ people in India, and $486702$ people worldwide and has claimed $16$ lives in India till now. We have discussed about the origin of the virus and possible measures to contain infection in our last post.\nIntroduction This is a post to show how we can incorporate quarantining effects in statistical modelling of epidemiology. In past few days of Shelter-in-place lockdown situation in Kolkata (and throughout the whole India from today onwards), me and one of my ingenious friend Subhrajyoty Roy (we were attending the same college before lockdown to purse Masters degree in Statistics), was reading about different epidemiological models available in the literature and using it to generate projections for the number of infected people in India, and this is a result of that reading and further independent developements.\nLoading the Packages and the Dataset We are using the same dataset source as before, except that we have updated it to include some of the current observations. Similar to before, we shall be using dplyr for data manipulation and summarization, lubridate for handling dates and times, and ggplot2 for plotting.\nHowever, due to some Monte Carlo simulation later, we shall be needing rjags and we shall use gtools for specification of some useful probability distributions.\nlibrary(readr)\rlibrary(dplyr)\rlibrary(lubridate)\rlibrary(ggplot2)\rlibrary(rjags)\rlibrary(gtools)\r Now, finally we load the updated dataset, which I have already downloaded from JHU CSSE, and manipulated to get the required form of data using the code discussed in my previous post here. We shall take a look at the last few columns to see how much we have updated.\ndat \u0026lt;- read_csv('./datasets/covid-19-data.csv')\rknitr::kable(tail(dat, 3))\r    State Country Lat Long Date Confirmed Deaths Recovered     Zhejiang China 29.1832 120.0934 2020-03-24 1240 1 1221   Zhejiang China 29.1832 120.0934 2020-03-25 1241 1 1221   Zhejiang China 29.1832 120.0934 2020-03-26 1243 1 1222    Description of eSIR Model The eSIR (Extended SIR) model is really similar to the SIR model, except for the fact that it includes a function that parametrizes the quarantining effects. As with SIR modelling, it has 3 different compartments, of states in which a person can be. This model has been developed very recently by Wang et al. The states are as follows:\ngraph LR\rA(Susceptible) --\u0026gt;|\u0026quot;\u0026amp;#946\u0026amp;#960(t)\u0026quot;| B(Infected)\rB --\u0026gt;|\u0026amp;#947| C(Removed)\r As described in previous post, Susceptibles are the general population, who is susceptible to get the disease from an infectious person. Infected state reperesents the persons who have the symptoms of the infection and is able to spread it. And finally, Recovered / Removed is the state when a person is recovered from the disease and gain immunity to it, or is dead. Let, $Y_t^S, Y_t^I, Y_t^R$ denotes the proportion of people in these states respectively at the time $t$. Note that $Y_t^S + Y_t^I + Y_t^R = 1$. $\\pi(t)$ denotes the proportion of people transiting from Susceptible to Infected state at time $t$, with the proportion being commensurate to the proportion of people transiting from Susceptible to Infected state at time $t$ in the original SIR modelling. Thus We can vary $\\pi(t)$ from time to time to perfectly capture the effect of quarantining. In other words, the rate at which a susceptible person becomes infected is not a time varying proportion, namely $\\beta \\pi(t)$, where $\\beta$ is the usual rate of transmission of the disease, while $\\pi(t)$ is the quarantining effect which might restrict movements of general public in order to make the effective transmission rate lower than the usual quantity $\\beta$.\nLet $\\theta_t=(\\theta_t^S, \\theta_t^I, \\theta_t^R)^T$ be the vector of underlying prevalence of the population in these three states. Since $Y_t^S, Y_t^I, Y_t^R$ are proportions, we model them via Beta distribution:\n$$\\begin{align} Y_t^I \\mid \\theta_t, \\tau \\sim \\text{Beta}(\\lambda^I\\theta_t^I,\\lambda^I(1-\\theta_t^I))\\\\\\\n\u0026amp; \\\\\\\nY_t^R \\mid \\theta_t, \\tau \\sim \\text{Beta}(\\lambda^R\\theta_t^R,\\lambda^R(1-\\theta_t^R))\\\\\\\n\\end{align}$$\nwhere $\\tau=(\\beta, \\gamma, \\theta_0^T, \\kappa, \\lambda^I, \\lambda^R)^T$, $\\beta$, $\\gamma$ are as in SIR model; $\\kappa$, $\\lambda^I, \\lambda^R$ are parameters governing the latent process we'll define soon.\nSince $\\theta_t$ is a probability, we specify a Dirichlet model for it:\n$$\\theta_t \\mid \\theta_{t-1}, \\tau \\sim \\text{Dirichlet} (k f(\\theta_{t-1}, \\beta, \\gamma))$$\nThese together is called a Beta-Dirichlet State Space Model.\nHere $f(\\cdot)$ is the solution of the system of ODEs:\n$$\\begin{align} \\dfrac{d\\theta_t^S}{dt} \u0026amp; = -\\pi(t)\\beta \\theta_t^S \\theta_t^I\\\\\\\n\u0026amp; \\\\\\\n\\dfrac{d\\theta_t^I}{dt} \u0026amp; = \\pi(t)\\beta \\theta_t^S \\theta_t^I - \\gamma \\theta_t^I\\\\\\\n\u0026amp; \\\\\\\n\\dfrac{d\\theta_t^R}{dt} \u0026amp; = \\gamma \\theta_t^I\\\\\\\n\\end{align}$$\nand this is exactly where the SIR modelling takes place. We solve this system of ODEs via Runge-Kutta(RK4) approximation.\nTo implement the Markov Chain Monte Carlo method, we need to specify prior for the hyperparameters $\\tau=(\\beta, \\gamma, \\theta_0^T, \\kappa, \\lambda^I, \\lambda^R)^{\\top}$. We do that as follows:\nWe initialize $\\theta_0$ via a distribution that uses the observed data:\n$$\\begin{align} \\theta_0^I \\sim \\text{Beta}(1, \\dfrac{1}{Y_1^I})\\\\\\\n\u0026amp; \\\\\\\n\\theta_0^R \\sim \\text{Beta}(1, \\dfrac{1}{Y_1^R})\\\\\\\n\u0026amp; \\\\\\\n\\theta_0^S= 1-\\theta_0^I-\\theta_0^R\\\\\\\n\\end{align}$$\nWe specify the other hyperparameters according to the SARS data in Hong-Kong.\n$$\\begin{align} R_0= \\dfrac{\\beta}{\\gamma} \\sim \\text{Log}\\mathbb{N}(1.099,0.096) \\implies \\mathbb{E}(R_0)=3.15, \\mathbb{V}(R_0)=1 \\\\\\\n\u0026amp; \\\\\\\n\\gamma \\sim \\text{Log}\\mathbb{N}(-2.955,0.910) \\implies \\mathbb{E}(\\gamma)=0.0117, \\mathbb{V}(\\gamma)=0.01 \\\\\\\n\u0026amp; \\\\\\\nk \\sim \\text{Gamma}(2, 0.0001)\\\\\\\n\u0026amp; \\\\\\\n\\lambda^I \\sim \\text{Gamma}(2, 0.0001)\\\\\\\n\u0026amp; \\\\\\\n\\lambda^R \\sim \\text{Gamma}(2, 0.0001)\\\\\\\n\\end{align}$$\nNow suppose , data upto time point $t_0$ are observed: $(Y_1, \\cdots Y_{t_0})$. We want to predict upto time point $T$. To this end, we generate $M$ MCMC samples, such that for $m \\in {1,\\cdots, M}$, $(Y_{t_0+1}^{(m)}, \\cdots, Y_T)$ is a draw from $Y_t \\mid \\theta_t, \\tau$. The algorihm is described below:\nfor $m$ in $1, \\cdots, M$\n$\\qquad$ for $t$ in $t_0+1,\\cdots, T$,\n$\\qquad \\qquad$ Draw $\\theta_t^{(m)}$ from $[\\theta_t \\mid \\theta_{t-1}^{(m)}, \\tau^{(m)}]$.\n$\\qquad \\qquad$ Draw $Y_t^{(m)}$ from $[Y_t \\mid \\theta_{t}^{(m)}, \\tau^{(m)} ]$\nFinally for each time point $t$, $t= t_0+1,\\cdots, T$ estimate $Y_t$ by $\\hat{Y}_t=\\dfrac{1}{M}\\displaystyle \\sum_{m=1}^M Y_t^{(m)}$.\nEstimation of eSIR Model Initialization Note that, we wish to have a lognormal distribution $R_0 \\sim LogN(\\mu, \\sigma^2)$, such that, $E(R_0), Var(R_0)$ is at a specified value. The specific reason is that, $R_0 = \\beta_0 / \\gamma_0$, which is a positive quantity, hence is better modelled by a gamma or lognormal distribution than a normal distribution, which has support as the whole of real line. Therefore, given $E(R_0) = a$, and $Var(R_0) = b$, we wish to figure out $\\mu, \\sigma$, the parmeters of the lognormal distribution. This can be obtained through the following simple formula and is implemented in the following function.\n$$\\sigma^2 = \\log\\left( \\dfrac{Var(R_0)}{E(R_0)^2} +1 \\right) \\qquad \\qquad \\mu = \\log(E(R_0)) - \\dfrac{\\sigma^2}{2}$$\nlognorm.param\u0026lt;-function(mu0,var0){\rvar \u0026lt;- log(var0/mu0^2+1)\rmu \u0026lt;- log(mu0)-var/2\rreturn(round(c(mu,var),3))\r}\r Now, we specify some control parameters, which specifies the initial $E(R_0), Var(R_0)$ and some other parameters, as well as the parameters for the markov chain (like the length of the chain, the number of parallel chains to construct in order to speed up the process, number of samples to define burn in period etc.) You may want to skip these technical details for now.\ninit.params \u0026lt;- list(R0 = 3.15, R0_sd = 1, gamma0 = 0.0117, gamma0_sd = 0.1)\rcontrol.params \u0026lt;- list(nchain=4, nadapt=1e4, ndraw=5e2, thin=10, nburnin=2e2)\rcontrol.params$mclen \u0026lt;- round(control.params$ndraw / control.params$thin) * control.params$nchain #number of MCMC draws in total\r Performing MCMC Now, we shall be creating a function called do.MCMC which takes the observed proportion of Infected (I), Removed ( R ), then the value of the function $\\pi(t)$ till the observed time period (and the control parameters). Then, it shall perform the MCMC step by generating the posterior sampels, and it shall output that posterior samples, which we shall later use to generate predictions, as well as get estimates.\nDefining the JAGS Code The very first thing to implement MCMC or any Bayesian Computation in rjags is the specification of a JAGS code. JAGS is the acronym for Just Another Gibbs Sampler, which is a program for simulation from Bayesian hierarchical models using Markov chain Monte Carlo (MCMC), developed by Martyn Plummer.\nJAGS code is mainly created based on two simple operations.\n  An assignment operator \u0026ldquo;\u0026lt;-\u0026rdquo; is used to denote a deterministic relation.\n  A tilde operator \u0026ldquo;~\u0026rdquo; is used to denote a stochastic relation. In this case, we have a probability distribution on right hand side, according to which the left hand side variable is being generated.\n  Based on the above operations, the following JAGS code creates the Bayesian model described above.\nmodel.string \u0026lt;- paste0(\u0026quot;\rmodel{\rfor(t in 2:(T_obs+1)){\rKm[t-1,1] \u0026lt;- -beta*pi[t-1]*theta[t-1,1]*theta[t-1,2]\rKm[t-1,9] \u0026lt;- gamma*theta[t-1,2]\rKm[t-1,5] \u0026lt;- -Km[t-1,1]-Km[t-1,9]\rKm[t-1,2] \u0026lt;- -beta*pi[t-1]*(theta[t-1,1]+0.5*Km[t-1,1])*(theta[t-1,2]+0.5*Km[t-1,5])\rKm[t-1,10] \u0026lt;- gamma*(theta[t-1,2]+0.5*Km[t-1,5])\rKm[t-1,6] \u0026lt;- -Km[t-1,2]-Km[t-1,10]\rKm[t-1,3] \u0026lt;- -beta*pi[t-1]*(theta[t-1,1]+0.5*Km[t-1,2])*(theta[t-1,2]+0.5*Km[t-1,6])\rKm[t-1,11] \u0026lt;- gamma*(theta[t-1,2]+0.5*Km[t-1,6])\rKm[t-1,7] \u0026lt;- -Km[t-1,3]-Km[t-1,11]\rKm[t-1,4] \u0026lt;- -beta*pi[t-1]*(theta[t-1,1]+Km[t-1,3])*(theta[t-1,2]+Km[t-1,7])\rKm[t-1,12] \u0026lt;- gamma*(theta[t-1,2]+Km[t-1,7])\rKm[t-1,8] \u0026lt;- -Km[t-1,4]-Km[t-1,12]\ralpha[t-1,1] \u0026lt;- theta[t-1,1]+(Km[t-1,1]+2*Km[t-1,2]+2*Km[t-1,3]+Km[t-1,4])/6\ralpha[t-1,2] \u0026lt;- theta[t-1,2]+(Km[t-1,5]+2*Km[t-1,6]+2*Km[t-1,7]+Km[t-1,8])/6\ralpha[t-1,3] \u0026lt;- theta[t-1,3]+(Km[t-1,9]+2*Km[t-1,10]+2*Km[t-1,11]+Km[t-1,12])/6\rtheta[t,1:3] ~ ddirch(k*alpha[t-1,1:3])\rI[t-1] ~ dbeta(lambdaI*theta[t,2],lambdaI*(1-theta[t,2]))\rR[t-1] ~ dbeta(lambdaR*theta[t,3],lambdaR*(1-theta[t,3]))\r}\rtheta[1,1] \u0026lt;- 1- theta[1,2]- theta[1,3]\rtheta[1,2] ~ dbeta(\u0026quot;,1,\u0026quot;,\u0026quot;,1/I[1],\u0026quot;)\rtheta[1,3] ~ dbeta(\u0026quot;,1,\u0026quot;,\u0026quot;,1/R[1],\u0026quot;)\rgamma ~ dlnorm(\u0026quot;,lognorm_gamma_param[1],\u0026quot;,\u0026quot;,1/lognorm_gamma_param[2],\u0026quot;)\rR0 ~ dlnorm(\u0026quot;,lognorm_R0_param[1],\u0026quot;,\u0026quot;,1/lognorm_R0_param[2],\u0026quot;)\rbeta \u0026lt;- R0*gamma\rk ~ dgamma(2,0.0001)\rlambdaI ~ dgamma(2,0.0001)\rlambdaR ~ dgamma(2,0.0001)\r}\r\u0026quot;)\r Here, init.params are to be passed accordingly in lognorm.param function to obtain the lognorm_gamma_param and lognorm_R0_param variables.\nPerforming MCMC Now, once we have the model.string containing the JAGS code, we need to open a connection object to that string. Because, rjags expect the JAGS code to be written in a file, a connection object can gimick the behavior of a file, just based on that string. Once we have the JAGS code ready, passing the data nodes in the JAGS model helps us in creating the posterior model.\nmodel.spec \u0026lt;- textConnection(model.string)\rposterior \u0026lt;- jags.model(model.spec, data=list('I'=I,'R'=R,'T_obs'=T_obs,'pi'=pi), n.chains =control.params$nchain, n.adapt = control.params$nadapt)\r Now, we first update the posterior for the burn-in period. In this time, the posterior generates samples are not close to the original sample, and hence we need to discard them. Typically, we set burn-in to be about $2000$ iterations. After that, we pass\nupdate(posterior, control.params$nburnin) # update the posterior for burn in times, for this time, do not monitor anything\rjags_sample \u0026lt;- jags.samples(posterior, c('theta','gamma','R0','beta','I','lambdaI','lambdaR','k'),\rn.iter = control.params$ndraw * control.params$nchain,\rthin = control.params$thin)\r So, we combine these into a function called do.MCMC which we shall use later.\nForecasting using eSIR model Now, since we have the MCMC samples obtained as the output of do.MCMC function, we can extend the chain using the exact simulation of the process described by the model above, and then, we can obtain the estimates of the proportion of infected and recovered people, as well as the confidence interval for that proportion.\nAgain, we shall create forecast.SIR function which takes in the output of do.MCMC, and then run the simulation chains starting from the MCMC samples. Finally, it computes the estimates and confidence intervals for the estimates of proportion of infected and removed from the samples from all the chains.\nExtract components of MCMC samples Here, we extract the components of MCMC samples from the output of do.MCMC function.\n# extract components from mcmc samples theta_pre \u0026lt;- array(as.mcmc.list(mcmc_sample$theta)[[1]], dim = c(control.params$mclen, T_obs+1, 3))\rR0_pre \u0026lt;- as.mcmc.list(mcmc_sample$R0)[[1]]\rgamma_pre \u0026lt;- as.mcmc.list(mcmc_sample$gamma)[[1]]\rbeta_pre \u0026lt;- as.mcmc.list(mcmc_sample$beta)[[1]]\rlambdaI_pre \u0026lt;- as.mcmc.list(mcmc_sample$lambdaI)[[1]]\rlambdaR_pre \u0026lt;- as.mcmc.list(mcmc_sample$lambdaR)[[1]]\rk_pre \u0026lt;- as.mcmc.list(mcmc_sample$k)[[1]]\r We also initialize blank arrays to store the future forecasts. Here, T_new is the number of time points for which new forecasting is to be done.\ntheta_post \u0026lt;- array(0, dim=c(control.params$mclen, T_new, 3))\rI_post \u0026lt;- matrix(NA, nrow=control.params$mclen, ncol=T_new)\rR_post \u0026lt;- matrix(NA, nrow=control.params$mclen, ncol=T_new)\r Peform Forecasting The following piece of code basically performs the forecasting starting from the last obtained posterior samples as obtained by MCMC. Now, let us go through the code step by step.\nfor(l in 1:control.params$mclen){\rthetalt1 \u0026lt;- theta_pre[l, T_obs+1, 1]\rthetalt2 \u0026lt;- theta_pre[l, T_obs+1, 2]\rthetalt3 \u0026lt;- theta_pre[l, T_obs+1, 3]\rbetal \u0026lt;- beta_pre[l]\rgammal \u0026lt;- gamma_pre[l]\rkt \u0026lt;- k_pre[l]\rlambdaIl \u0026lt;- lambdaI_pre[l]\rlambdaRl \u0026lt;- lambdaR_pre[l]\rif (betal\u0026lt;0 | gammal\u0026lt;0 | thetalt1\u0026lt;0 | thetalt2\u0026lt;0 |thetalt3\u0026lt;0) { next }\rfor(t in 1:T_new ){\r# perform runge kutta\rKm \u0026lt;- numeric(12)\ralpha_post \u0026lt;- numeric(3)\rKm[1] \u0026lt;- -betal*pi_new[t]*thetalt1*thetalt2\rKm[9] \u0026lt;- gammal*thetalt2\rKm[5] \u0026lt;- -Km[1]-Km[9]\rKm[2] \u0026lt;- -betal*pi_new[t]*(thetalt1+0.5*Km[1])*(thetalt2+0.5*Km[5])\rKm[10] \u0026lt;- gammal*(thetalt2+0.5*Km[5])\rKm[6] \u0026lt;- -Km[2]-Km[10]\rKm[3] \u0026lt;- -betal*pi_new[t]*(thetalt1+0.5*Km[2])*(thetalt2+0.5*Km[6])\rKm[11] \u0026lt;- gammal*(thetalt2+0.5*Km[6])\rKm[7] \u0026lt;- -Km[3]-Km[11]\rKm[4] \u0026lt;- -betal*pi_new[t]*(thetalt1+Km[3])*(thetalt2+Km[7])\rKm[12] \u0026lt;- gammal*(thetalt2+Km[7])\rKm[8] \u0026lt;- -Km[4]-Km[12]\ralpha_post[1] \u0026lt;- thetalt1+(Km[1]+2*Km[2]+2*Km[3]+Km[4])/6\ralpha_post[2] \u0026lt;- thetalt2+(Km[5]+2*Km[6]+2*Km[7]+Km[8])/6\ralpha_post[3] \u0026lt;- thetalt3+(Km[9]+2*Km[10]+2*Km[11]+Km[12])/6\rthetalt_tmp \u0026lt;- rdirichlet(1, kt* abs(alpha_post))\rthetalt1 \u0026lt;- theta_post[l,t,1] \u0026lt;- thetalt_tmp[1]\rthetalt2 \u0026lt;- theta_post[l,t,2] \u0026lt;- thetalt_tmp[2]\rthetalt3 \u0026lt;- theta_post[l,t,3] \u0026lt;- thetalt_tmp[3]\rI_post[l,t] \u0026lt;- rbeta(1,lambdaIl*thetalt2,lambdaIl*(1-thetalt2))\rR_post[l,t] \u0026lt;- rbeta(1,lambdaRl*thetalt3,lambdaRl*(1-thetalt3))\r}\r}\r   The outer loop runs for each of the MCMC chains generated by mcmc_output.\n  If any of $\\beta, \\gamma, \\theta^S,\\theta^I, \\theta^R$ turns out to be less than $0$, the chain is stopped and is not proceeded further.\n  In the inner loop, for each new timepoint, we perform the Runge Kutta methods of numerically solving the differential equations,\n  At the end of the loop, we have all the estimates for proportion of Infected and Removed, as well as the three latent proportion parameters $\\theta$ which accords with the underlying mathematical model of SIR.\n  Here, pi_new[t] = pi[T_obs + t].\n  Derivation of 3 important dates Associated with the estimation of eSIR model, there are three important dates, which we should output from our algorithm.\n  The date when $\\dfrac{d^2 \\theta^I_t}{dt^2} = 0$. This date is the time, when the rate of change in the proportion of infected people starts to be decreasing, so we are in a hopeful scenario that the number of new infected cases is going to be decreasing over time.\n  The date when $\\dfrac{d \\theta^I_t}{dt} = 0$, i.e. the date from when the number of new recovered cases starts to exceed the number of new infected cases. From this time onwards, the epidemic nature of the disease vanishes.\n  The date when $\\theta^I_t = 0$. However, it is impossible to have this proportion equal to $0$, in finite times. Therefore, we shall be looking for a date, when $\\theta^I_t \u0026lt; \\epsilon$, where $\\epsilon$ is a very small quantity, which can be treated readily at any time.\n  To simplify the calculation of derivative, we track the quantity $(\\beta \\pi(t) \\theta^S_t\\theta^I_t - \\gamma \\theta^I_t)$ over time, which is equal to the derivative due to SIR modelling.\nThe following picture taken from the paper by Wang et al. shows the concept clearly.\ntheta_diff_pre \u0026lt;- theta_pre[, 1:T_obs, 2] * sweep(beta_pre %*% t(pi[1:T_obs]) * theta_pre[, 1:T_obs, 1], MARGIN = 1, STATS = gamma_pre)\rtheta_diff_post \u0026lt;- theta_post[, , 2] * sweep(beta_pre %*% t(pi[(T_obs+1):(T_obs+T_new)]) * theta_post[, , 1], MARGIN = 1, STATS = gamma_pre)\rtheta_diff \u0026lt;- cbind(theta_diff_pre, theta_diff_post)\r Now, we find the maximum of each row of theta_diff and locate the timepoints, where theta_diff is changing its signs. They should give up the required first and second important dates.\nfirst_dates \u0026lt;- apply(theta_diff, 1, which.max)\rsecond_dates \u0026lt;- apply(theta_diff, 1, function(x) { length(x) + 1 - which(cumprod(rev(x \u0026lt;= 0)) == 0)[1] } ) # the first time it becomes negative and stays negative throughout\r Now, that we have the dates for each chain, let us take the mean, median, and quantiles, which would give us estimates and confidence intervals for such dates.\nconf.quant \u0026lt;- c(conf.level/2, 0.5, 1-conf.level/2) # conf.level is the confidence coefficients for the confidence interval\rfirst_date_summary \u0026lt;- c( mean(first_dates, na.rm = T), quantile(first_dates, probs = conf.quant, na.rm = T) )\rsecond_date_summary \u0026lt;- c( mean(second_dates, na.rm = T), quantile(second_dates, probs = conf.quant, na.rm = T) )\r Summarising the forecast outputs Once we have perform forecasting for each and every chain of the MCMC samples, we can aggregated them to obtain the mean, median, and quantiles, which would give us estimates for the proportion of people in state infected and removed, as well as the confidence interval for those estimates.\n# till the observed time points\rthetaI_band \u0026lt;- t(apply(theta_pre[,-1,2] , 2, quantile, probs=conf.quant, na.rm=T)) thetaR_band\u0026lt;- t(apply(theta_pre[,-1,3] , 2, quantile, probs=conf.quant, na.rm=T))\rthetaI_mean \u0026lt;- colMeans(theta_pre[, -1, 2], na.rm = T)\rthetaR_mean \u0026lt;- colMeans(theta_pre[, -1, 3], na.rm = T)\r# for the new time points\rYI_band \u0026lt;- t(apply(I_post , 2, quantile, probs=conf.quant, na.rm=T)) YR_band\u0026lt;- t(apply(R_post , 2, quantile, probs=conf.quant, na.rm=T))\rYI_mean \u0026lt;- colMeans(I_post, na.rm = T)\rYR_mean \u0026lt;- colMeans(R_post, na.rm = T)\r# combine into a data frame\rinfected.dat \u0026lt;- data.frame( rbind( cbind(thetaI_mean, thetaI_band, rep(\u0026quot;pre\u0026quot;, T_obs) ), cbind(YI_mean, YI_band, rep(\u0026quot;post\u0026quot;, T_new) ) ) )\rremoved.dat \u0026lt;- data.frame( rbind( cbind(thetaR_mean, thetaR_band, rep(\u0026quot;pre\u0026quot;, T_obs) ), cbind(YR_mean, YR_band, rep(\u0026quot;post\u0026quot;, T_new) ) ) )\rcolnames(infected.dat) \u0026lt;- c(\u0026quot;mean\u0026quot;, \u0026quot;lower\u0026quot;, \u0026quot;median\u0026quot;, \u0026quot;upper\u0026quot;)\rcolnames(removed.dat) \u0026lt;- c(\u0026quot;mean\u0026quot;, \u0026quot;lower\u0026quot;, \u0026quot;median\u0026quot;, \u0026quot;upper\u0026quot;)\r Then, we can return a list comprising of these two datasets, as well as the summary corresponding to the first and second date obtained earlier. This whole piece of code, is compressed into a function called forecast.SIR, which we shall call later.\nChecking Performance of eSIR Now, we shall be using the data for Italy, in order to figure out how our eSIR model performs for this data.\nPerformance for Italy According to Worldometers sources, the projected population for Italy is about 6 crores. Based on that, we compute the observed proportion of the infected and removed (including deaths and recovered), and fit the eSIR model. The following code calls the do.MCMC function and performs the MCMC fitting. Here, we use 4 weeks of data, of the available 5 weeks of data, and we shall try to forecast for the last week, to see how the model performed.\nAlso, the $\\pi(t)$ function choosen for Italy is as follows;\n$$\\pi(t) = \\begin{cases} 1 \u0026amp; \\text{ if } t \u0026lt; \\text{4th March, 2020}\\\\\\\n0.25 \u0026amp; \\text{ if } t \u0026gt; \\text{9th March, 2020}\\\\\\\n0.5 \u0026amp; \\text{ otherwise }\\\\\\\n\\end{cases}$$\nsubdat \u0026lt;- dat %\u0026gt;% mutate(Removed = Deaths + Recovered) %\u0026gt;% filter(Country == \u0026quot;Italy\u0026quot; \u0026amp; Removed \u0026gt; 0)\rN \u0026lt;- 60550075\rR \u0026lt;- subdat$Removed / N\rI \u0026lt;- subdat$Confirmed/N - R\rpi0 \u0026lt;- ifelse(subdat$Date \u0026lt; as.Date('2020-03-04'), 1, ifelse(subdat$Date \u0026gt; as.Date('2020-03-09'), 0.25, 0.5))\rinit.params \u0026lt;- list(R0 = 3.15, R0_sd = 1, gamma0 = 0.0117, gamma0_sd = 0.1)\rcontrol.params \u0026lt;- list(nchain=4, nadapt=1e4, ndraw=5e2, thin=10, nburnin=2e2)\rcontrol.params$mclen \u0026lt;- round(control.params$ndraw / control.params$thin) * control.params$nchain mcmc_samples \u0026lt;- do.MCMC(I[1:28], R[1:28], pi0[1:28], init.params, control.params)\r You should see something like this, which tells you that the JAGS code for MCMC is running properly.\nCompiling model graph\rResolving undeclared variables\rAllocating nodes\rGraph information:\rObserved stochastic nodes: 56\rUnobserved stochastic nodes: 35\rTotal graph size: 1591\rInitializing model\r As we see from the following plot, the predictions for the last week is underestimating the true proportions. However, the observed proportions lie within the bound of $95%$ confidence band.\npreds \u0026lt;- forecast.SIR(7, 28, mcmc_samples, pi = pi0, control.params = control.params, start.date = \u0026quot;2020-02-21\u0026quot;)\rggplot(preds$infected, aes(x = date)) + geom_ribbon(aes(ymin = lower, ymax = upper, fill = phase), alpha = 0.25) +\rgeom_line(aes(y = mean, color = phase), size = 1) +\rlabs(x = \u0026quot;Date\u0026quot;, y = \u0026quot;P(Infected)\u0026quot;) +\rgeom_point(data = subdat, aes(x = Date, y = (Confirmed - Removed)/N), color = \u0026quot;black\u0026quot;)\r However, if we assume that, the Italy government maintains the current lockdown indefinitely, then $\\pi(t) = 0.25$ will continue to remain. In such case, the important dates (as mentioned above) for change in the rate of newly infected can be obtained, as shown in the following plot.\npi0 \u0026lt;- c(pi0, rep(0.25, 200))\rpreds \u0026lt;- forecast.SIR(7+200, 28, mcmc_samples, pi = pi0, control.params = control.params, start.date = \u0026quot;2020-02-21\u0026quot;)\rggplot(preds$infected, aes(x = date)) + geom_ribbon(aes(ymin = lower, ymax = upper, fill = phase), alpha = 0.25) +\rgeom_line(aes(y = mean, color = phase), size = 1) +\rgeom_vline(xintercept = preds$first.date[1], color = \u0026quot;brown\u0026quot;) + geom_vline(xintercept = preds$second.date[1], color = \u0026quot;blue4\u0026quot;) +\rlabs(x = \u0026quot;Date\u0026quot;, y = \u0026quot;P(Infected)\u0026quot;) +\rgeom_point(data = subdat, aes(x = Date, y = (Confirmed - Removed)/N), color = \u0026quot;black\u0026quot;) +\rgeom_text(x = preds$first.date[1] - 1, y = 0, label = format(preds$first.date[1], \u0026quot;%b %d\u0026quot;), size = 4 ) +\rgeom_text(x = preds$second.date[1] - 1, y = 0, label = format(preds$second.date[1], \u0026quot;%b %d\u0026quot;), size = 4 )\r Therefore, in Italy, at about June 22, we should see decreasing increments of newly infected persons, and from August 1 onwards, the proportion of infected people should decline.\nEstimation for India However, our main concern is to find out the situation of India based on this eSIR modelling. Here, we shall use the $\\pi(t)$ function as follows, as per various decision taken by the Government, like restriction on international flights, Janta Curfew and full scale lockdowns etc.\n$$\\pi(t) = \\begin{cases} 1 \u0026amp; \\text{ if } t \u0026lt; \\text{15th March, 2020}\\\\\\\n0.95 \u0026amp; \\text{ if } \\text{15th March, 2020} \u0026lt; t \u0026lt; \\text{19th March, 2020}\\\\\\\n0.9 \u0026amp; \\text{ if } \\text{19th March, 2020} \u0026lt; t \u0026lt; \\text{22th March, 2020}\\\\\\\n0.5 \u0026amp; \\text{ if } \\text{22th March, 2020} \u0026lt; t \u0026lt; \\text{25th March, 2020}\\\\\\\n0.1 \u0026amp; \\text{ if } t \u0026gt; \\text{25th March, 2020}\\\\\\\n\\end{cases}$$\nAlso, note that in India, many places are rural in nature, while most of the urban population and neighbourhood areas are more susceptible to get the disease than others, due to availablity of metro cities and international airports. So, rather than using the whole population size i.e. $131$ crores as $N$, we shall use about $350$ lakhs as the adjusted population size.\nsubdat \u0026lt;- dat %\u0026gt;% mutate(Removed = Deaths + Recovered, Infected = Confirmed - Removed) %\u0026gt;%\rfilter(Country == \u0026quot;India\u0026quot; \u0026amp; Removed \u0026gt; 0 \u0026amp; Infected \u0026gt; 0)\rN \u0026lt;- 350e5 # adjusted population for metro cities and neighbourhood areas\rR \u0026lt;- subdat$Removed / N\rI \u0026lt;- subdat$Infected/N\rpi0 \u0026lt;- ifelse(subdat$Date \u0026lt; as.Date('2020-03-15'), 1, ifelse(subdat$Date \u0026lt; as.Date('2020-03-19'), 0.9, ifelse(subdat$Date \u0026lt; as.Date('2020-03-22'), 0.8, ifelse(subdat$Date \u0026lt; as.Date('2020-03-25'), 0.5, 0.1)) ))\rinit.params \u0026lt;- list(R0 = 12.48, R0_sd = 1, gamma0 = 0.117, gamma0_sd = 1)\rcontrol.params \u0026lt;- list(nchain=4, nadapt=1e4, ndraw=5e2, thin=5, nburnin=2e2)\rcontrol.params$mclen \u0026lt;- round(control.params$ndraw / control.params$thin) * control.params$nchain mcmc_samples \u0026lt;- do.MCMC(I, R, pi0, init.params, control.params)\r And finally, we perform the prediction till the end of the lockdown, i.e. till $14$-th April, to see the effect of quaranting.\npi1 \u0026lt;- c(pi0, rep(0.1, 19)) # from 27th March, it is 19 days of lockdown left preds \u0026lt;- forecast.SIR(19, 25, mcmc_samples, pi = pi1, control.params = control.params, start.date = \u0026quot;2020-03-02\u0026quot;)\rggplot(preds$infected, aes(x = date)) + geom_ribbon(aes(ymin = lower, ymax = upper, fill = phase), alpha = 0.25) +\rgeom_line(aes(y = mean, color = phase), size = 1) +\rlabs(x = \u0026quot;Date\u0026quot;, y = \u0026quot;P(Infected)\u0026quot;) +\rgeom_point(data = subdat, aes(x = Date, y = Infected/N), color = \u0026quot;black\u0026quot;)\r Although it seems that the mean proportion is overestimated during the ovserved period, however the effect of quanting seems to work to a moderate extent, as the estimated proportion stays more or less at the same level. The exact count of the infected people at the end of lockdown, provided that it is maintained properly, should be about $1317$ many infected persons, and about $2114$ confirmed cases of COVID-19.\nSimilar to Italy, if we extend its forecast for some more days, and keep the same level of quaranting, the model predictions are given in the following plot.\npi2 \u0026lt;- c(pi0, rep(0.1, 200)) preds \u0026lt;- forecast.SIR(200, 25, mcmc_samples, pi = pi2, control.params = control.params, start.date = \u0026quot;2020-03-02\u0026quot;)\rggplot(preds$infected, aes(x = date)) + geom_ribbon(aes(ymin = lower, ymax = upper, fill = phase), alpha = 0.25) +\rgeom_line(aes(y = mean, color = phase), size = 1) +\rgeom_vline(xintercept = preds$first.date[1], color = \u0026quot;brown\u0026quot;, size = 1, linetype = \u0026quot;dashed\u0026quot;) + geom_vline(xintercept = preds$second.date[1], color = \u0026quot;blue4\u0026quot;, size = 1, linetype = \u0026quot;dashed\u0026quot;) +\rlabs(x = \u0026quot;Date\u0026quot;, y = \u0026quot;P(Infected)\u0026quot;) +\rgeom_point(data = subdat, aes(x = Date, y = (Confirmed - Removed)/N), color = \u0026quot;black\u0026quot;) +\rgeom_text(x = preds$first.date[1] - 7, y = 2e-4, label = format(preds$first.date[1], \u0026quot;%b %d\u0026quot;), size = 4 ) +\rgeom_text(x = preds$second.date[1] + 7, y = 3e-4, label = format(preds$second.date[1], \u0026quot;%b %d\u0026quot;), size = 4 )\r Therefore, as it seems, if we keep the lockdown (as it is now), based on the data, it might take till October to have the proportion of infected people becoming insignificant, provided we keep the same level of quanranting effect. However, from March 17, we should see a decrease in the rate of increment in the number of infected, and from March 29 onwards, we should be at a position from where the number of newly infected persons per day starts to decrease.\nSince, it is very economically and physically dissatisfying to be in a lockdown (or state of home quarantine till October, where Durga Puja festival is going to occur), we might want to go outside. In that case, assuming $\\pi(t)$ increases to $0.5$, which is indeed less than 1, due to our increasing awareness of the scenario, then, the predicted situation would look like this.\npi3 \u0026lt;- c(pi0, rep(0.1, 19), rep(0.5, 2 * 365)) preds \u0026lt;- forecast.SIR(2 * 365 + 19, 25, mcmc_samples, pi = pi3, control.params = control.params, start.date = \u0026quot;2020-03-02\u0026quot;)\rpreds$infected$upper_new \u0026lt;- pmin(preds$infected$upper, 0.05) # just for visual purpose\rggplot(preds$infected, aes(x = date)) + geom_ribbon(aes(ymin = lower, ymax = upper_new, fill = phase), alpha = 0.25) +\rgeom_line(aes(y = mean, color = phase), size = 1) +\rgeom_vline(xintercept = preds$first.date[1], color = \u0026quot;brown\u0026quot;, size = 1, linetype = \u0026quot;dashed\u0026quot;) + geom_vline(xintercept = preds$second.date[1], color = \u0026quot;blue4\u0026quot;, size = 1, linetype = \u0026quot;dashed\u0026quot;) +\rlabs(x = \u0026quot;Date\u0026quot;, y = \u0026quot;P(Infected)\u0026quot;) +\rgeom_point(data = subdat, aes(x = Date, y = (Confirmed - Removed)/N), color = \u0026quot;black\u0026quot;) +\rgeom_text(x = preds$first.date[1] - 7, y = 2e-4, label = format(preds$first.date[1], \u0026quot;%b %d\u0026quot;), size = 4 ) +\rgeom_text(x = preds$second.date[1] + 7, y = 3e-4, label = format(preds$second.date[1], \u0026quot;%b %d\u0026quot;), size = 4 )\r This scenario would be very severe for us, since it would affect about $4%$ of the urban population, on about June 13, and then it would start to decrease gradually. However, it would take almost 2 years, to make this epidemic insignificant, provided there will be no generally accepted antiviral medicine for COVID-19 till then.\nHence, we must avoid such situation at all costs, and to counter it, we must stay home, at a shelter in place home quaranting atmosphere.\nConclusion This eSIR model is not perfect. No statistical model is. But the main idea and examples that we are seeing currently all over the world, should give us a hint about what is to come.\nThere are several backdrops in eSIR model.\n  It does not talk about underreporting. When you are in a place like India, underreporting is a major issue, as there might be some people who are affected by coronavirus, but lightly takes their symptoms as seasonal cold.\n  In the basis of SIR model, we assume the existence of only 3 states. To incorporate the effect of quaranting, we only considering the people in Infected state. However, there might be people who are infected, and can spread the disease, yet they do not have the symptoms, and hence does not fall under the effect of quaranting.\n  We shall try to deal with these shortcomings in our next post, where we shall consider building more out of this particular model.\nWHO Guidelines to STAY SAFE:\n  The best way to prevent and slow down transmission is be well informed about the COVID-19 virus, the disease it causes and how it spreads.\n  Wash your hands frequently with an alcohol based rub or soap.\n  Maintain social distancing.\n  Avoid touching eyes, nose and mouth.\n  Practice respiratory hygiene.\n  If you have fever, cough and difficulty breathing, seek medical care early.\n  Stay informed and follow advice given by your healthcare provider.\n  Protect yourselves and protect others.\n  Signing Off\n$\\qquad \u0026mdash;$ Soham Bonnerjee \u0026amp; Subhrajyoty Roy\n Stay home, Stay safe, Keep safe your friends, families and neighbours.\n ","date":1585353600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585353600,"objectID":"1786e5d167a62dd6721b8ba4e6bda417","permalink":"/post/esir-modelling/","publishdate":"2020-03-28T00:00:00Z","relpermalink":"/post/esir-modelling/","section":"post","summary":"This is the second post in a series of posts to give a basic understanding of statistical modelling of epidemiology. In this post, we shall explore the performance of stochastic eSIR model. Then, we shall use it to generate projections for the epidemic situation in India.","tags":null,"title":"eSIR - An Epidemiological Model incoportating Quarantining Effect","type":"post"},{"authors":["Soham Bonnerjee","Subhrajyoty Roy"],"categories":null,"content":"The Current Global Scenario At the end of December 2019, a cluster of an unknown pneumonia like cases were reported in Wuhan, a city in the Hubei province, China. They quickly identified that the source of the infection was a novel coronavirus belonging to the coronavirus family, which includes the virus related to the outbreaks of Severe Acute Respiratory Syndrome (SARS) from 2002-2004 and Middle East Respiratory Syndrome (MERS) in 2012. It spread through and outside of Wuhan, resulting in an rapidly escalating and deadly contagious epidemic throughout China, followed by an increasing number of cases in other countries throughout the world.\nOn January 30, the WHO declared coronavirus a global emergency as the death toll in China jumped to 170, with 7,711 cases reported in the country, where the virus had spread to all 31 provinces. In mid-February WHO announced that the new coronavirus would be called \u0026ldquo;COVID-19\u0026rdquo;.\nChina's bold approach to contain the rapid spread of this new respiratory pathogen by massive lockdowns and electronic surveillance measures has changed the changed the course of the epidemic . The number of new infections reported in China has been declining gradually. With over 422,915 reported cases and more than 18,543 recorded deaths worldwide , the outbreak of COVID-19 has surpassed the toll of the 2002-2003 SARS outbreak, which also originated in China and is expected to continue to increase. Although the infection originated in China, now the epicenter of the pandemic is Europe, which now has more cases reported each day than China did at the height of its outbreak. In Italy alone the COVID-19 has infected more than 69,000 people and killed at least 6,800. There is an increasing number of cases in several EU/EEA countries without epidemiological links to explain the source of transmission. The speed with which COVID-19 can cause nationally incapacitating epidemics once transmission within the community is established indicates that it is likely that in a few weeks or even days, similar situations to those seen in China and Italy may be seen in other EU/EEA countries or the UK, as more countries report evidence of community transmission. The COVID-19 virus spreads primarily through droplets of saliva or discharge from the nose when an infected person coughs or sneezes. At the time of this writing, there are no specific vaccines or treatments for COVID-19 which is generally accepted.\nIntroduction This is a post to give a basic understanding of statistical modelling of epidemiology. In past few days of Shelter-in-place lockdown situation in Kolkata (and throughout the whole India from today onwards), me and one of my friend Subhrajyoty Roy (we were attending the same college before lockdown to purse Masters degree in Statistics), was reading about different epidemiological models available in the literature and using it to generate projections for the number of infected people in India.\nIn this post, we shall explore the performance of deterministic SIR model which to be fitted using a least squares procedure. Then, we shall use it to generate projections for the epidemic situation in India, till the end of this lockdown, which is currently annouced to be remain till April 14, 2020, about 3 weeks from today.\nExploratory Analysis Before proceeding with introducing the SIR model, let us first read the data into R (which is what we are going to use through out), and perform some exploratory analysis. We shall be using the tidyverse library, which is a collection of some very useful packages for data proprocessing and exploratory analysis.\nlibrary(readr)\rlibrary(dplyr)\rlibrary(tidyr)\rlibrary(lubridate)\rlibrary(ggplot2)\r For the related coronavirus, there are may different sources available. Many international organizations like WHO (World Health Organization), ECDC (European Centre for Disease Prevention and Control) and many national governments are releasing day to day basis publicly available data. As well as different news agencies are also collecting and compileing data from the hospitals and different other sources on a regular basis. John Hopkins University (JHU) CSSE department has also released a dataset compiled from the collection of these sources in a github repository here.\nThe datasets are being updated on a daily basis. We shall use this data provided by JHU CSSE.\nconfirmed.dat \u0026lt;- read_csv('./datasets/time_series_19-covid-Confirmed.csv')\rdeaths.dat \u0026lt;- read_csv('./datasets/time_series_19-covid-Deaths.csv')\rrecovered.dat \u0026lt;- read_csv('./datasets/time_series_19-covid-Recovered.csv')\rconfirmed.dat \u0026lt;- confirmed.dat %\u0026gt;%\rrename( State = `Province/State`, Country = `Country/Region` ) %\u0026gt;% gather(key = \u0026quot;Date\u0026quot;, value = \u0026quot;Confirmed\u0026quot;, -c(1:4) ) %\u0026gt;%\rmutate(Date = mdy(Date))\rdeaths.dat \u0026lt;- deaths.dat %\u0026gt;%\rrename( State = `Province/State`, Country = `Country/Region` ) %\u0026gt;% gather(key = \u0026quot;Date\u0026quot;, value = \u0026quot;Deaths\u0026quot;, -c(1:4) ) %\u0026gt;% mutate(Date = mdy(Date))\rrecovered.dat \u0026lt;- recovered.dat %\u0026gt;%\rrename( State = `Province/State`, Country = `Country/Region` ) %\u0026gt;% gather(key = \u0026quot;Date\u0026quot;, value = \u0026quot;Recovered\u0026quot;, -c(1:4) ) %\u0026gt;%\rmutate(Date = mdy(Date))\r# merge all of them together\rdat \u0026lt;- Reduce(merge, list(confirmed.dat, deaths.dat, recovered.dat))\rdat \u0026lt;- as_tibble(dat)\rknitr::kable(head(dat, 5))\r    State Country Lat Long Date Confirmed Deaths Recovered     Adams, IN US 39.8522 -77.2865 2020-01-22 0 0 0   Adams, IN US 39.8522 -77.2865 2020-01-23 0 0 0   Adams, IN US 39.8522 -77.2865 2020-01-24 0 0 0   Adams, IN US 39.8522 -77.2865 2020-01-25 0 0 0   Adams, IN US 39.8522 -77.2865 2020-01-26 0 0 0    Now we shall try to see how the total number of Confirmed, deaths and recovered people changed across the globe.\ntemp \u0026lt;- dat %\u0026gt;% group_by(Date) %\u0026gt;% summarise(Confirmed = sum(Confirmed), Deaths = sum(Deaths), Recovered = sum(Recovered)) %\u0026gt;%\rgather(key = \u0026quot;Variable\u0026quot;, value = \u0026quot;Count\u0026quot;, -Date)\rggplot(temp, aes(x = Date, y = Count, color = Variable)) + geom_line(size = 1)\r The situation is very severe, as the current trend in exponentially increasing in terms of confirmed cases, and the growth rate of recovered is sufficiently slow. If we particular focus on the situation of India, (after 1st March, 2020),\nAs of now, there are very less number of recoveries, some deaths, and a lot of (about 400) affected people. We have also compiled how these changes occurs spatially in different countries. They are shown below.\nSIR Model Description The SIR model is one of the compartmental models in epidemiology which is used to mathematically model the spread of an infectious disease. This model was firstly introduced by William Ogilvy Kermack and A. G. McKendrick, and named as Kermack-McKendrick Model. However, with time, this model has obtained several variants, each being better than the one before.\nSIR modelling starts with defining 3 different compartments, of states in which a person can be. The states are as follows:\ngraph LR;\rS(Susceptible) -- I(Infected);\rI(Infected) -- R(Recovered / Removed);\r Susceptibles are the general population, who is susceptible to get the disease from an infectious person. Infected state reperesents the persons who have the symptoms of the infection and is able to spread it. And finally, Recovered or Removed is the state when a person is recovered from the disease and gain immunity to it, or is dead. Let, $Y_t^S, Y_t^I, Y_t^R$ dentoes the number of people in these states respectively at the time $t$. The corresponding proportions are denoted by $\\theta_t^S, \\theta_t^I$ and $\\theta_t^R$, where the proportion is defined as the number of people in a state divided by the total number of people, i.e. the population count. Note that, since these three states are assumed to be exhaustive, hence $Y_t^S + Y_t^I + Y_t^R = N$, where $N$ is the total population of the particular region under study.\nThe mathematical relations between these quantities are defined as follows:\n$$ \\begin{align} \\dfrac{d\\theta_t^S}{dt} \u0026amp; = -\\beta \\theta_t^S \\theta_t^I\\\\\\\n\u0026amp; \\\\\\\n\\dfrac{d\\theta_t^I}{dt} \u0026amp; = \\beta \\theta_t^S \\theta_t^I - \\gamma \\theta_t^I\\\\\\\n\u0026amp; \\\\\\\n\\dfrac{d\\theta_t^R}{dt} \u0026amp; = \\gamma \\theta_t^I\\\\\\\n\\end{align} $$\nNote that, since $Y_t^S + Y_t^I + Y_t^R = N$, we have $\\theta_t^S + \\theta_t^I + \\theta_t^R = 1$, which is constant. Hence, we must have,\n$$ \\dfrac{d\\theta_t^S}{dt} + \\dfrac{d\\theta_t^I}{dt} + \\dfrac{d\\theta_t^R}{dt} = 0 $$\nwhich is satisfied by the mathematical formulation. In this, $\\beta, \\gamma$ are unknown parameters which is to be estimated from the data.\nThese mathematical equations did not drop from the sky. Let us understand how these mathematical formula emerges from an intuitive points of view.\n  We consider the third equation first. It models the change in the number of recovered people. Now, the change in the number (or proportion) of recovered people can occur only when an infectious person, gets treatment, which happens with rate $\\gamma$, which can be interpreted as the recovery rate of an infectious person. Therefore, it changes by the amount $\\gamma \\theta_t^I$.\n  Now we consider the first equation. It models the change in the number of susceptible population. The change in susceptible population occurs, when an infectious person comes in contact with a susceptible person, and the infection spreads. Now, there are $Y_t^I Y_t^S$ many interactions possible, and each interaction would spread the virus with rate $\\beta$ say. Considering proportions, we have the change being equal to $-\\beta\\theta_t^I\\theta_t^S$, with the negative sign showing that number of susceptibles can only decrease.\n  Due to the restriction, $\\dfrac{d\\theta_t^S}{dt} + \\dfrac{d\\theta_t^I}{dt} + \\dfrac{d\\theta_t^R}{dt} = 0$, the choice of $\\dfrac{d\\theta_t^I}{dt}$ can be justfied from previous points.\n  A very important measure in this model is the quantity;\n$$R_0 = \\dfrac{\\beta}{\\gamma}$$\nThis basically interprets as the average number of people an infectious person infects before recovering or dying. So, if $R_0 \u0026lt; 1$, then an infectious person infects less than one person in average before recovering, which means the infection pandemic will eventually die out. Whereas, if $R_0 \u0026gt; 1$, then an infectious person infects more than one person in average before recovering, hence the number of infected would increase exponentially and eventually all of the population will become infected.\nEstimation of SIR Model There are two possible ways of estimation of the parameters of an SIR model.\n  A deterministic estimation.\n  A stochastic estimation.\n  A deterministic estimation does not require any other assumptions on the model parameters, as well as the data. It basically works simply on the basis of solution to the above differential equations. However, a stochastic estimation requires specifications of the distributional assumptions on the data, as well as model parameters. In this post, we are going to use only a deterministic setup of the model as explained in the mathematical formulation, nothing more.\nFor this reason, we shall use Runge Kutta methods of numerically solving a system of differential equations, under some particular choice of the model parameters $\\beta, \\gamma$. However, as we solve the differential equations, we shall be able to obtain estimates $\\hat{Y}_t^S, \\hat{Y}_t^I$ and $\\hat{Y}_t^R$. Then, we can use a Least Squares approach to solve this problem, to estimate $\\beta, \\gamma$ as;\n$$ (\\hat{\\beta}, \\hat{\\gamma}) = \\min_{\\beta, \\gamma} \\sum_t \\left[ \\left(Y_t^S - \\hat{Y}_t^S\\right)^2 + \\left(Y_t^I - \\hat{Y}_t^I\\right)^2 + \\left(Y_t^R - \\hat{Y}_t^R\\right)^2 \\right] $$\nTo this end, we write the function pred.SIR and LS.SIR which performs the prediction given the initial value and parameters, and computes the value of the objective function written above by tallying it with the observed data.\npred.SIR \u0026lt;- function(n_time, beta, gamma, init.theta) {\rtheta \u0026lt;- matrix(0, nrow = n_time, ncol = 3)\rtheta[1, ] \u0026lt;- init.theta / sum(init.theta)\rfor (t in 2:n_time) {\r# for each time, create the Runge Kutta approximation\rKm \u0026lt;- numeric(12) # 12 coefficients are needed\r# computes coefficients of runge kutta\rKm[1] \u0026lt;- - beta * theta[t-1,1] * theta[t-1,2]\rKm[9] \u0026lt;- gamma * theta[t-1,2]\rKm[5] \u0026lt;- -Km[1]-Km[9]\rKm[2] \u0026lt;- - beta * (theta[t-1,1]+ 0.5*Km[1]) * (theta[t-1,2]+0.5*Km[5])\rKm[10] \u0026lt;- gamma*(theta[t-1,2]+0.5*Km[5])\rKm[6] \u0026lt;- -Km[2]-Km[10]\rKm[3] \u0026lt;- -beta*(theta[t-1,1]+0.5*Km[2])*(theta[t-1,2]+0.5*Km[6])\rKm[11] \u0026lt;- gamma*(theta[t-1,2]+0.5*Km[6])\rKm[7] \u0026lt;- -Km[3]-Km[11]\rKm[4] \u0026lt;- -beta*(theta[t-1,1]+Km[3])*(theta[t-1,2]+Km[7])\rKm[12] \u0026lt;- gamma*(theta[t-1,2]+Km[7])\rKm[8] \u0026lt;- -Km[4]-Km[12]\rinnov.S \u0026lt;- ( Km[1] + 2 *Km[2] + 2*Km[3] + Km[4])/6\rinnov.I \u0026lt;- ( Km[5] + 2 *Km[6] + 2*Km[7] + Km[8])/6\rinnov.R \u0026lt;- ( Km[9] + 2 *Km[10] + 2*Km[11] + Km[12])/6\rtheta[t, ] \u0026lt;- theta[(t-1), ] + c(innov.S, innov.I, innov.R)\rtheta[t, ] \u0026lt;- theta[t, ]/sum(theta[t, ])\r}\rreturn(theta)\r}\rLS.SIR \u0026lt;- function(params, Y) {\rbeta \u0026lt;- params[1]\rgamma \u0026lt;- params[2]\rn_time \u0026lt;- nrow(Y)\rN \u0026lt;- sum(Y[1, ])\rinit.theta \u0026lt;- Y[1, ] / N\rpreds \u0026lt;- pred.SIR(n_time, beta, gamma, init.theta)\rreturn( sum((Y - preds * N )^2) ) }\r Performance of SIR model Estimation for Hong Kong, China We choose the Hong Kong province in China to see how SIR model performs. According to World Bank data, the province Hong Kong is home to about $73.9$ lakhs people. Therefore, we have $N = 73.9\\times 10^5$, in our model.\nN \u0026lt;- 73.9e5 # population of Hong Kong\rtemp \u0026lt;- dat %\u0026gt;% filter(Country == \u0026quot;China\u0026quot; \u0026amp; State == \u0026quot;Hong Kong\u0026quot;) %\u0026gt;% mutate(Removed = Deaths + Recovered, Susceptible = N - Removed - Confirmed) %\u0026gt;% select(Date, Susceptible, Confirmed, Removed)\rknitr::kable(head(temp))\r    Date Susceptible Confirmed Removed     2020-01-22 7390000 0 0   2020-01-23 7389998 2 0   2020-01-24 7389998 2 0   2020-01-25 7389995 5 0   2020-01-26 7389992 8 0   2020-01-27 7389992 8 0    As you can see, the first appearence of Coronavirus in Hong Kong is on 23rd of Janurary, 2020. So, we should use the data from 2nd row onwards to fit into SIR model. We shall be using the data corresponding to $61$ days, i.e. till 23rd of May, 2020. Among this, we shall be training the model using data of first $47$ days, and then we build the prediction for next $14$ days, to see the performance of the fitted model. We shall be using optim function of R to optimize our objective function in order to find Least Sqaures estimate.\nY \u0026lt;- as.matrix(temp[2:48, 2:4])\rops \u0026lt;- optim(par = c(1e-2, 1e-5), fn = LS.SIR, method = \u0026quot;BFGS\u0026quot;, Y = Y, control = list(trace = 1))\r initial value 552556.538521 iter 10 value 68951.183015\rfinal value 65031.692121 converged\r ops$par[1] / ops$par[2] # R0\r [1] 3.149289\r Now that we have the estimated parameters, we can simply generate predictions for last $14$ days, using this pred.SIR method. Before that, estimate of $R_0$ turns out to be higher than 1, thereby showing the seriousness of the COVID-19 epidemic situation.\n# since predictions are proportions, we multiply with the population to get the count estimates\rpreds \u0026lt;- pred.SIR(14, ops$par[1], ops$par[2], as.matrix(temp[49, 2:4])) * N\rpred.dat \u0026lt;- tibble(Date = temp$Date[49:62], Pred.Confirmed = preds[, 2], Pred.Removed = preds[, 3])\rpred.dat \u0026lt;- left_join(temp, pred.dat, by = c(\u0026quot;Date\u0026quot; = \u0026quot;Date\u0026quot;)) # create a full dataset containing predicted data as well\rggplot( pred.dat , aes(x = Date) ) +\rgeom_line(aes(y = Confirmed), color = \u0026quot;black\u0026quot;, size = 1) +\rgeom_line(aes(y = Pred.Confirmed), color = \u0026quot;blue\u0026quot;, size = 1, linetype = \u0026quot;dashed\u0026quot;)\r Therefore, we see that SIR model overestimates the true number by about $75$ people at the last day. Nevertheless, this is simple model, which performs fairly good. However, it would have been nice if we could give a confidence interval around that estimate.\nPerformance for India We perform the same exercise for India as well. For India, the population is huge (about $131$ crores) and there is lesser amount of data available, although the first confirmed case of COVID-19 was identified in 30th January, 2020. We have data on $54$ days, among which we shall use all the data before last week, and generate predictions for last week, to visualize its performance.\nThe $R_0$ coefficient turns out to be 12.4850813, which is severe as it is a lot more than $1$.\npreds \u0026lt;- pred.SIR(7, ops$par[1], ops$par[2], as.matrix(temp[48, 2:4])) * N\rpred.dat \u0026lt;- tibble(Date = temp$Date[48:54], Pred.Confirmed = preds[, 2], Pred.Removed = preds[, 3])\rpred.dat \u0026lt;- left_join(temp, pred.dat, by = c(\u0026quot;Date\u0026quot; = \u0026quot;Date\u0026quot;)) # create a full dataset containing predicted data as well\rggplot( pred.dat , aes(x = Date) ) +\rgeom_line(aes(y = Confirmed), color = \u0026quot;black\u0026quot;, size = 1) +\rgeom_line(aes(y = Pred.Confirmed), color = \u0026quot;blue\u0026quot;, size = 1, linetype = \u0026quot;dashed\u0026quot;)\r Yet in this case, the SIR model does a underestimation in determining the number of confirmed cases by about $100$ cases. Therefore, the seriousness of the pandemic situation is even worse than what is depicted by the number $R_0$, i.e. 12.4850813, it is enitrely possible that the true $R_0$ value is even more at the last week, thereby showing on average an infectious person is infecting more than $12$ persons, which is bad, seriously bad.\nPredictions till the end of the Lockdown To make this prediction, we use all the available datapoints for estimation of the parameters. So, we refit the model.\nY \u0026lt;- as.matrix(temp[, 2:4])\rops \u0026lt;- optim(par = c(1e-2, 1e-5), fn = LS.SIR, method = \u0026quot;BFGS\u0026quot;, Y = Y)\rpreds \u0026lt;- pred.SIR(22, ops$par[1], ops$par[2], as.matrix(temp[54, 2:4])) * N\rpred.dat \u0026lt;- tibble(Date = temp$Date[54] + 1:22, Pred.Confirmed = preds[, 2], Pred.Removed = preds[, 3])\rpred.dat \u0026lt;- full_join(temp, pred.dat, by = c(\u0026quot;Date\u0026quot; = \u0026quot;Date\u0026quot;)) # create a full dataset containing predicted data as well\rggplot( pred.dat , aes(x = Date) ) +\rgeom_line(aes(y = Confirmed), color = \u0026quot;black\u0026quot;, size = 1) +\rgeom_line(aes(y = Pred.Confirmed), color = \u0026quot;blue\u0026quot;, size = 1, linetype = \u0026quot;dashed\u0026quot;)\r So, if there was no lockdown happening, the prediction of confirmed cases in India by middle of April would have be about $4000$.\nNote that SIR is the best-case scenario, hence this is an underestimate. Thus without any quarantining intervention, the situation looks grim; But all hope is not lost, for in the next post, we'll show how different measures of quarantining, including lockdown, help decrease the rate of increase in confirmed cases. Till then stay united, and stay safe. We would get through this hard time.\nWHO Guidelines to STAY SAFE:\n  The best way to prevent and slow down transmission is be well informed about the COVID-19 virus, the disease it causes and how it spreads.\n  Wash your hands frequently with an alcohol based rub or soap.\n  Maintain social distancing.\n  Avoid touching eyes, nose and mouth.\n  Practice respiratory hygiene.\n  If you have fever, cough and difficulty breathing, seek medical care early.\n  Stay informed and follow advice given by your healthcare provider.\n  Protect yourselves and protect others.\n   Signing off $\\qquad \u0026mdash; $ Soham Bonnerjee \u0026amp; Subhrajyoty Roy   Stay informed, Stay home, Stay safe.\n ","date":1585094400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585094400,"objectID":"70d60b5afd92410eaa1a403802f6f1c5","permalink":"/post/covid19-project/","publishdate":"2020-03-25T00:00:00Z","relpermalink":"/post/covid19-project/","section":"post","summary":"This is a post to give a basic understanding of statistical modelling of epidemiology. In this post, we shall explore the performance of deterministic SIR model which to be fitted using a least squares procedure. Then, we shall use it to generate projections for the epidemic situation in India","tags":null,"title":"SIR Modelling of COVID-19 Pandemic situation","type":"post"},{"authors":null,"categories":null,"content":"We first discuss the theories behind Multiple Correspondence Analysis, and then proceed to discuss some applications. Find out more in the PDF and Slides.\n","date":1576800000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1576800000,"objectID":"7d2742584684bc286062fe31ace081f0","permalink":"/project/multiple-correspondence-analysis/","publishdate":"2019-12-20T00:00:00Z","relpermalink":"/project/multiple-correspondence-analysis/","section":"project","summary":"A brief overview of Multiple Correspondence Analysis","tags":["Others"],"title":"Multiple Correspondence Analysis","type":"project"},{"authors":null,"categories":null,"content":"An Exoplanet or Extrasolar planet is an earth-like planet outside the Solar System. The Kepler Space Observatory has analyzed 10000 odd Kepler Object of Interests, and designated them either Exoplanet, or False Positive. This designation follows complex mathematical formulae that's not open to public. We try to emulate Kepler's analysis using simple statistical tools that also gives us interpretability. Find out more in the slides.\n","date":1571616000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1571616000,"objectID":"e226653eedb18c8f04453fca9b73bf26","permalink":"/project/exoplanet-hunting/","publishdate":"2019-10-21T00:00:00Z","relpermalink":"/project/exoplanet-hunting/","section":"project","summary":"We predict a planet's designation using Kepler data.","tags":["Others"],"title":"Exoplanet Hunting- A Statistical Approach","type":"project"},{"authors":["Soham Bonnerjee","Subhrajyot Roy","Ritwik Bhaduri"],"categories":null,"content":"","date":1567296000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567296000,"objectID":"966884cc0d8ac9e31fab966c4534e973","permalink":"/publication/journal-article/","publishdate":"2019-09-01T00:00:00Z","relpermalink":"/publication/journal-article/","section":"publication","summary":"tfdfhgc","tags":["Source Themes"],"title":"Onset Detection- A New Approach to QBH System","type":"publication"},{"authors":null,"categories":null,"content":"Haseman-Elston's 1970 paper has been a seminal one in the field of Quantitaive Trait Loci (QTL) mapping. In this project, we discuss the methods of the paper, popularly known as Haseman-Elston Regression in the context of Sibling-Pair data. Find out more in the slides.\n","date":1552435200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1552435200,"objectID":"71e952fa962d4351a345489c1d31908e","permalink":"/project/haseman-elston-regression/","publishdate":"2019-03-13T00:00:00Z","relpermalink":"/project/haseman-elston-regression/","section":"project","summary":"We discuss the Haseman-Elston Regression in the context of QTL Mapping.","tags":["Bio-Statistics"],"title":"Mapping Human QTL usiing Sib-Pair Data","type":"project"},{"authors":null,"categories":null,"content":"We introduce the Juggling Markov Chain and discuss its various properties, and try to find the order of its Mixing Time. Find more in the pdf.\n","date":1532995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1532995200,"objectID":"fc2cbddb8ead24f98ca01441ec3b90f3","permalink":"/project/juggling-markov-chain/","publishdate":"2018-07-31T00:00:00Z","relpermalink":"/project/juggling-markov-chain/","section":"project","summary":"We investigate the Mixing Time of Juggling Markov Chain by Warrington.","tags":["Others"],"title":"On Mixing Time of  Juggling Markov Chain","type":"project"}]